{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習フロー\n",
    "Kaggleの Home Credit Default Risk コンペティションを題材に、機械学習の実践的な流れを学びます。特に適切な 検証 を行い、高い 汎化性能 のあるモデルを完成させることを目指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】クロスバリデーション\n",
    "事前学習期間では検証データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。<br>\n",
    "<br>\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。<br>\n",
    "<br>\n",
    "[sklearn.model_selection.KFold — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリ使用量の節約関数\n",
    "# ソースコードはkernelより取得\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 59.54 MB\n",
      "Decreased by 79.2%\n",
      "test\n",
      "Memory usage of dataframe is 45.00 MB\n",
      "Memory usage after optimization is: 9.40 MB\n",
      "Decreased by 79.1%\n"
     ]
    }
   ],
   "source": [
    "#データの読み込み\n",
    "print(\"train\")\n",
    "train_raw = import_data('/Users/tamiyagt/Documents/Machine Learning/02_Kaggle/home credit/application_train.csv')\n",
    "print(\"test\")\n",
    "test_raw = import_data('/Users/tamiyagt/Documents/Machine Learning/02_Kaggle/home credit/application_test.csv')\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">データの前処理として、前回の課題で行ったものを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# あとでデータ分割するために要素数を把握\n",
    "ntrain = train_raw.shape[0]\n",
    "ntest = test_raw.shape[0]\n",
    "\n",
    "# 目的変数をyに格納\n",
    "target = train_raw['TARGET']\n",
    "# SK_ID_CURRをX_idに格納\n",
    "sk_id = test_raw['SK_ID_CURR']\n",
    "\n",
    "# trainとtestを結合\n",
    "all_data = pd.concat([train_raw, test_raw]).reset_index(drop=True)\n",
    "all_data.drop(['SK_ID_CURR', 'TARGET'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損値を含む列数：67\n",
      "-----------------\n",
      "                              Missing Values  % of Total Values\n",
      "COMMONAREA_MEDI                       248360               69.7\n",
      "COMMONAREA_AVG                        248360               69.7\n",
      "COMMONAREA_MODE                       248360               69.7\n",
      "NONLIVINGAPARTMENTS_MEDI              246861               69.3\n",
      "NONLIVINGAPARTMENTS_MODE              246861               69.3\n",
      "NONLIVINGAPARTMENTS_AVG               246861               69.3\n",
      "FONDKAPREMONT_MODE                    243092               68.2\n",
      "LIVINGAPARTMENTS_MODE                 242979               68.2\n",
      "LIVINGAPARTMENTS_MEDI                 242979               68.2\n",
      "LIVINGAPARTMENTS_AVG                  242979               68.2\n",
      "FLOORSMIN_MODE                        241108               67.7\n",
      "FLOORSMIN_MEDI                        241108               67.7\n",
      "FLOORSMIN_AVG                         241108               67.7\n",
      "YEARS_BUILD_MODE                      236306               66.3\n",
      "YEARS_BUILD_MEDI                      236306               66.3\n",
      "YEARS_BUILD_AVG                       236306               66.3\n",
      "OWN_CAR_AGE                           235241               66.0\n",
      "LANDAREA_AVG                          210844               59.2\n",
      "LANDAREA_MEDI                         210844               59.2\n",
      "LANDAREA_MODE                         210844               59.2\n",
      "BASEMENTAREA_MEDI                     207584               58.3\n",
      "BASEMENTAREA_AVG                      207584               58.3\n",
      "BASEMENTAREA_MODE                     207584               58.3\n",
      "NONLIVINGAREA_MEDI                    195766               55.0\n",
      "NONLIVINGAREA_MODE                    195766               55.0\n",
      "NONLIVINGAREA_AVG                     195766               55.0\n",
      "EXT_SOURCE_1                          193910               54.4\n",
      "ELEVATORS_MEDI                        189080               53.1\n",
      "ELEVATORS_MODE                        189080               53.1\n",
      "ELEVATORS_AVG                         189080               53.1\n",
      "WALLSMATERIAL_MODE                    180234               50.6\n",
      "APARTMENTS_MODE                       179948               50.5\n",
      "APARTMENTS_MEDI                       179948               50.5\n",
      "APARTMENTS_AVG                        179948               50.5\n",
      "ENTRANCES_MODE                        178407               50.1\n",
      "ENTRANCES_AVG                         178407               50.1\n",
      "ENTRANCES_MEDI                        178407               50.1\n",
      "HOUSETYPE_MODE                        177916               49.9\n",
      "LIVINGAREA_MEDI                       177902               49.9\n",
      "LIVINGAREA_MODE                       177902               49.9\n",
      "LIVINGAREA_AVG                        177902               49.9\n",
      "FLOORSMAX_MEDI                        176341               49.5\n",
      "FLOORSMAX_AVG                         176341               49.5\n",
      "FLOORSMAX_MODE                        176341               49.5\n",
      "YEARS_BEGINEXPLUATATION_AVG           172863               48.5\n",
      "YEARS_BEGINEXPLUATATION_MEDI          172863               48.5\n",
      "YEARS_BEGINEXPLUATATION_MODE          172863               48.5\n",
      "TOTALAREA_MODE                        171055               48.0\n",
      "EMERGENCYSTATE_MODE                   167964               47.1\n",
      "OCCUPATION_TYPE                       111996               31.4\n",
      "EXT_SOURCE_3                           69633               19.5\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK             47568               13.4\n",
      "AMT_REQ_CREDIT_BUREAU_DAY              47568               13.4\n",
      "AMT_REQ_CREDIT_BUREAU_MON              47568               13.4\n",
      "AMT_REQ_CREDIT_BUREAU_QRT              47568               13.4\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR             47568               13.4\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR             47568               13.4\n",
      "NAME_TYPE_SUITE                         2203                0.6\n",
      "DEF_30_CNT_SOCIAL_CIRCLE                1050                0.3\n",
      "OBS_60_CNT_SOCIAL_CIRCLE                1050                0.3\n",
      "DEF_60_CNT_SOCIAL_CIRCLE                1050                0.3\n",
      "OBS_30_CNT_SOCIAL_CIRCLE                1050                0.3\n",
      "EXT_SOURCE_2                             668                0.2\n",
      "AMT_GOODS_PRICE                          278                0.1\n",
      "AMT_ANNUITY                               36                0.0\n",
      "CNT_FAM_MEMBERS                            2                0.0\n",
      "DAYS_LAST_PHONE_CHANGE                     1                0.0\n"
     ]
    }
   ],
   "source": [
    "# 欠損率の確認\n",
    "def get_miss(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "    mis_val_table = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'}\n",
    "    )\n",
    "\n",
    "    # 表を欠損率順に並べ替え、欠損値０のサンプルは除外\n",
    "    mis_val_table_sort = mis_val_table[\n",
    "        mis_val_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "    \n",
    "    return mis_val_table_sort\n",
    "\n",
    "miss_data = get_miss(all_data)\n",
    "\n",
    "print(\"欠損値を含む列数：{}\".format(miss_data.shape[0]))\n",
    "print(\"-----------------\")\n",
    "print(miss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損値を含む列数：0\n",
      "-----------------\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, % of Total Values]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 補完する変数を特定\n",
    "features = ['EXT_SOURCE_1','EXT_SOURCE_2', 'EXT_SOURCE_3','NAME_TYPE_SUITE',\n",
    "            'DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "            'OBS_30_CNT_SOCIAL_CIRCLE','AMT_GOODS_PRICE','AMT_ANNUITY','CNT_FAM_MEMBERS',\n",
    "            'DAYS_LAST_PHONE_CHANGE']\n",
    "\n",
    "# カテゴリー変数を特定\n",
    "categorical = all_data[features].select_dtypes(exclude='number')\n",
    "# 数値変数を特定\n",
    "numerical = all_data[features].select_dtypes(include='number')\n",
    "\n",
    "# カテゴリー変数を最頻値で補完\n",
    "for f in categorical:\n",
    "    all_data[f].fillna(all_data[f].mode()[0], inplace=True)\n",
    "\n",
    "# # 数値変数を中央値で補完\n",
    "for f in numerical:\n",
    "    all_data[f].fillna(all_data[f].median(), inplace=True)    \n",
    "\n",
    "    \n",
    "# 欠損値10%以上の列を削除\n",
    "all_data_drop = all_data.dropna(axis=1, thresh=350000)\n",
    "\n",
    "# データを確認\n",
    "miss_data = get_miss(all_data_drop)\n",
    "\n",
    "print(\"欠損値を含む列数：{}\".format(miss_data.shape[0]))\n",
    "print(\"-----------------\")\n",
    "print(miss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columns were label encoded.\n",
      "Data shape:  (356255, 160)\n"
     ]
    }
   ],
   "source": [
    "# LabelEncodingを行う\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in all_data_drop:\n",
    "    if all_data_drop[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(all_data_drop[col].unique())) <= 2:\n",
    "            # Fit the data\n",
    "            le.fit(all_data_drop[col])\n",
    "            # Transform both all_data\n",
    "            all_data_drop[col] = le.transform(all_data_drop[col])\n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('{} columns were label encoded.'.format(le_count))\n",
    "\n",
    "# One-Hot Encodingを行う\n",
    "# ソースコードはKaggleのkernelから取得\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "all_data_lab = pd.get_dummies(all_data_drop)\n",
    "\n",
    "print('Data shape: ', all_data_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "all_data_lab = all_data_lab.copy()\n",
    "\n",
    "# DTIを追加\n",
    "all_data_lab['DTI'] = all_data_lab['AMT_CREDIT']/all_data_lab['AMT_INCOME_TOTAL']\n",
    "# DTI計算の元となった特徴量を削除\n",
    "all_data_lab.drop(columns=['AMT_CREDIT', 'AMT_INCOME_TOTAL'], inplace=True)\n",
    "\n",
    "# 多次元特徴量の生成\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "all_data_poly = poly.fit_transform(\n",
    "    all_data_lab.loc[:, ['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DTI', 'EXT_SOURCE_2', 'EXT_SOURCE_3']])\n",
    "feature_names = poly.get_feature_names(\n",
    "    input_features = ['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DTI', 'EXT_SOURCE_2', 'EXT_SOURCE_3'])\n",
    "\n",
    "# # 多次元特徴量生成の元となった特徴量を削除（重複するため）\n",
    "all_data_lab.drop(columns=['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DTI', 'EXT_SOURCE_2', 'EXT_SOURCE_3'], inplace=True)\n",
    "\n",
    "# # 元のデータフレームと多次元特徴量を結合\n",
    "all_data_lab = pd.concat((all_data_lab,\n",
    "                             pd.DataFrame(data=all_data_poly, columns=feature_names)),\n",
    "                             axis=1)\n",
    "\n",
    "# trainとtestに分割\n",
    "train = all_data_lab[:ntrain]\n",
    "test = all_data_lab[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DataFrameをndarrayに変換\n",
    "X = np.array(train)\n",
    "y = np.array(target)\n",
    "\n",
    "# データを分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">本課題で検証した各手法の成績を記録するためのデータフレームを作成する。<br>\n",
    ">各行が分割検証法、各列がパラメータチューニング法を示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>Grid</th>\n",
       "      <th>Random</th>\n",
       "      <th>Bayesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Holdout</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kfold</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Default Grid Random Bayesian\n",
       "Holdout     NaN  NaN    NaN      NaN\n",
       "Kfold       NaN  NaN    NaN      NaN\n",
       "SSS         NaN  NaN    NaN      NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各手法の結果を表に記載\n",
    "summary = pd.DataFrame(index=['Holdout', 'Kfold', 'SSS'], columns=['Default', 'Grid', 'Random', 'Bayesian'])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### ベースラインモデルの学習（ホールドアウト検証）\n",
    ">上記にて生成した抽出特徴量に対して学習を行う。以後はこのモデルをベースラインと呼ぶ。\n",
    ">- 分類器：Logistic Regression (max iterations = 5000)\n",
    ">- 標準化手法：Quantile Transformation (Gaussian Dist.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベースモデルのAUC ROC値：0.738888\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegressionベースモデルの正解率を検証\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "# 特徴量の重要性を取得\n",
    "features_names = list(train.columns)\n",
    "\n",
    "feature_importance_values = abs(lr.coef_.flatten())\n",
    "feature_importances = pd.DataFrame({'feature': features_names, 'importance': feature_importance_values})\n",
    "\n",
    "lr_pred = lr.predict_proba(X_val_std)\n",
    "\n",
    "score = roc_auc_score(y_val, lr_pred[:,1])\n",
    "\n",
    "print(\"ベースモデルのAUC ROC値：{:5f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">特徴量が多く、ハイパーパラメータチューニングに時間を要するため、重要性上位の特徴量抽出して学習を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMT_GOODS_PRICE^2</td>\n",
       "      <td>1.598194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMT_GOODS_PRICE DTI</td>\n",
       "      <td>1.288114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMT_ANNUITY DTI</td>\n",
       "      <td>1.050981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMT_ANNUITY AMT_GOODS_PRICE</td>\n",
       "      <td>0.828995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMT_ANNUITY EXT_SOURCE_3</td>\n",
       "      <td>0.471827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMT_GOODS_PRICE EXT_SOURCE_3</td>\n",
       "      <td>0.341941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAME_INCOME_TYPE_Maternity leave</td>\n",
       "      <td>0.326158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXT_SOURCE_3^2</td>\n",
       "      <td>0.325988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMT_GOODS_PRICE EXT_SOURCE_2</td>\n",
       "      <td>0.324959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NAME_INCOME_TYPE_Student</td>\n",
       "      <td>0.316060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>0.308616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EXT_SOURCE_2 EXT_SOURCE_3</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AMT_ANNUITY EXT_SOURCE_2</td>\n",
       "      <td>0.217778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.216742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.212714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FLAG_DOCUMENT_4</td>\n",
       "      <td>0.211513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>0.197922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AMT_ANNUITY^2</td>\n",
       "      <td>0.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AMT_GOODS_PRICE</td>\n",
       "      <td>0.189648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FLAG_DOCUMENT_10</td>\n",
       "      <td>0.183982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FLAG_DOCUMENT_2</td>\n",
       "      <td>0.171516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EXT_SOURCE_1</td>\n",
       "      <td>0.166696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DTI EXT_SOURCE_3</td>\n",
       "      <td>0.165898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FLAG_DOCUMENT_17</td>\n",
       "      <td>0.135276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NAME_INCOME_TYPE_Pensioner</td>\n",
       "      <td>0.129943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CODE_GENDER_XNA</td>\n",
       "      <td>0.124989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ORGANIZATION_TYPE_Trade: type 4</td>\n",
       "      <td>0.124339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DTI^2</td>\n",
       "      <td>0.122627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DTI</td>\n",
       "      <td>0.118427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FLAG_DOCUMENT_15</td>\n",
       "      <td>0.113054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             feature  importance\n",
       "0                  AMT_GOODS_PRICE^2    1.598194\n",
       "1                AMT_GOODS_PRICE DTI    1.288114\n",
       "2                    AMT_ANNUITY DTI    1.050981\n",
       "3        AMT_ANNUITY AMT_GOODS_PRICE    0.828995\n",
       "4           AMT_ANNUITY EXT_SOURCE_3    0.471827\n",
       "5       AMT_GOODS_PRICE EXT_SOURCE_3    0.341941\n",
       "6   NAME_INCOME_TYPE_Maternity leave    0.326158\n",
       "7                     EXT_SOURCE_3^2    0.325988\n",
       "8       AMT_GOODS_PRICE EXT_SOURCE_2    0.324959\n",
       "9           NAME_INCOME_TYPE_Student    0.316060\n",
       "10                       AMT_ANNUITY    0.308616\n",
       "11         EXT_SOURCE_2 EXT_SOURCE_3    0.231200\n",
       "12          AMT_ANNUITY EXT_SOURCE_2    0.217778\n",
       "13                      EXT_SOURCE_3    0.216742\n",
       "14                      EXT_SOURCE_2    0.212714\n",
       "15                   FLAG_DOCUMENT_4    0.211513\n",
       "16                     DAYS_EMPLOYED    0.197922\n",
       "17                     AMT_ANNUITY^2    0.189900\n",
       "18                   AMT_GOODS_PRICE    0.189648\n",
       "19                  FLAG_DOCUMENT_10    0.183982\n",
       "20                   FLAG_DOCUMENT_2    0.171516\n",
       "21                      EXT_SOURCE_1    0.166696\n",
       "22                  DTI EXT_SOURCE_3    0.165898\n",
       "23                  FLAG_DOCUMENT_17    0.135276\n",
       "24        NAME_INCOME_TYPE_Pensioner    0.129943\n",
       "25                   CODE_GENDER_XNA    0.124989\n",
       "26   ORGANIZATION_TYPE_Trade: type 4    0.124339\n",
       "27                             DTI^2    0.122627\n",
       "28                               DTI    0.118427\n",
       "29                  FLAG_DOCUMENT_15    0.113054"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴量を重要性の高い順に表示\n",
    "feature_importances.sort_values('importance', ascending = False, ignore_index=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_INCOME_TYPE_Maternity leave</th>\n",
       "      <th>NAME_INCOME_TYPE_Student</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_ANNUITY AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_ANNUITY DTI</th>\n",
       "      <th>AMT_ANNUITY EXT_SOURCE_3</th>\n",
       "      <th>AMT_GOODS_PRICE^2</th>\n",
       "      <th>AMT_GOODS_PRICE DTI</th>\n",
       "      <th>AMT_GOODS_PRICE EXT_SOURCE_2</th>\n",
       "      <th>AMT_GOODS_PRICE EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_3^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>8.669875e+09</td>\n",
       "      <td>49595.855469</td>\n",
       "      <td>3443.355957</td>\n",
       "      <td>1.232010e+11</td>\n",
       "      <td>7.047689e+05</td>\n",
       "      <td>92291.750000</td>\n",
       "      <td>48930.906250</td>\n",
       "      <td>0.019434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>4.032145e+10</td>\n",
       "      <td>171022.593750</td>\n",
       "      <td>19051.982422</td>\n",
       "      <td>1.275770e+12</td>\n",
       "      <td>5.411152e+06</td>\n",
       "      <td>702628.437500</td>\n",
       "      <td>602804.437500</td>\n",
       "      <td>0.284827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>9.112500e+08</td>\n",
       "      <td>13500.000000</td>\n",
       "      <td>4924.072266</td>\n",
       "      <td>1.822500e+10</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>75080.562500</td>\n",
       "      <td>98481.445312</td>\n",
       "      <td>0.532159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>8.816891e+09</td>\n",
       "      <td>68758.882812</td>\n",
       "      <td>15843.429688</td>\n",
       "      <td>8.820900e+10</td>\n",
       "      <td>6.879015e+05</td>\n",
       "      <td>193166.015625</td>\n",
       "      <td>158506.343750</td>\n",
       "      <td>0.284827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>1.121700e+10</td>\n",
       "      <td>92321.000000</td>\n",
       "      <td>11669.429688</td>\n",
       "      <td>2.631690e+11</td>\n",
       "      <td>2.166000e+06</td>\n",
       "      <td>165572.750000</td>\n",
       "      <td>273783.687500</td>\n",
       "      <td>0.284827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>6.200550e+09</td>\n",
       "      <td>44565.222656</td>\n",
       "      <td>14707.467773</td>\n",
       "      <td>5.062500e+10</td>\n",
       "      <td>3.638572e+05</td>\n",
       "      <td>153369.140625</td>\n",
       "      <td>120080.562500</td>\n",
       "      <td>0.284827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>2.700337e+09</td>\n",
       "      <td>44930.617188</td>\n",
       "      <td>6405.097656</td>\n",
       "      <td>5.062500e+10</td>\n",
       "      <td>8.423438e+05</td>\n",
       "      <td>26092.529297</td>\n",
       "      <td>120080.562500</td>\n",
       "      <td>0.284827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>1.753771e+10</td>\n",
       "      <td>132782.281250</td>\n",
       "      <td>6561.565918</td>\n",
       "      <td>3.422250e+11</td>\n",
       "      <td>2.591068e+06</td>\n",
       "      <td>313352.062500</td>\n",
       "      <td>128040.164062</td>\n",
       "      <td>0.047905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>6.455498e+09</td>\n",
       "      <td>43731.062500</td>\n",
       "      <td>13358.188477</td>\n",
       "      <td>1.020802e+11</td>\n",
       "      <td>6.915157e+05</td>\n",
       "      <td>164274.171875</td>\n",
       "      <td>211231.937500</td>\n",
       "      <td>0.437097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>3.315431e+10</td>\n",
       "      <td>210503.562500</td>\n",
       "      <td>5597.068848</td>\n",
       "      <td>4.556250e+11</td>\n",
       "      <td>2.892857e+06</td>\n",
       "      <td>478234.875000</td>\n",
       "      <td>76918.031250</td>\n",
       "      <td>0.012985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NAME_INCOME_TYPE_Maternity leave  NAME_INCOME_TYPE_Student  \\\n",
       "0                                      0                         0   \n",
       "1                                      0                         0   \n",
       "2                                      0                         0   \n",
       "3                                      0                         0   \n",
       "4                                      0                         0   \n",
       "...                                  ...                       ...   \n",
       "307506                                 0                         0   \n",
       "307507                                 0                         0   \n",
       "307508                                 0                         0   \n",
       "307509                                 0                         0   \n",
       "307510                                 0                         0   \n",
       "\n",
       "        AMT_ANNUITY  AMT_ANNUITY AMT_GOODS_PRICE  AMT_ANNUITY DTI  \\\n",
       "0           24700.5                 8.669875e+09     49595.855469   \n",
       "1           35698.5                 4.032145e+10    171022.593750   \n",
       "2            6750.0                 9.112500e+08     13500.000000   \n",
       "3           29686.5                 8.816891e+09     68758.882812   \n",
       "4           21865.5                 1.121700e+10     92321.000000   \n",
       "...             ...                          ...              ...   \n",
       "307506      27558.0                 6.200550e+09     44565.222656   \n",
       "307507      12001.5                 2.700337e+09     44930.617188   \n",
       "307508      29979.0                 1.753771e+10    132782.281250   \n",
       "307509      20205.0                 6.455498e+09     43731.062500   \n",
       "307510      49117.5                 3.315431e+10    210503.562500   \n",
       "\n",
       "        AMT_ANNUITY EXT_SOURCE_3  AMT_GOODS_PRICE^2  AMT_GOODS_PRICE DTI  \\\n",
       "0                    3443.355957       1.232010e+11         7.047689e+05   \n",
       "1                   19051.982422       1.275770e+12         5.411152e+06   \n",
       "2                    4924.072266       1.822500e+10         2.700000e+05   \n",
       "3                   15843.429688       8.820900e+10         6.879015e+05   \n",
       "4                   11669.429688       2.631690e+11         2.166000e+06   \n",
       "...                          ...                ...                  ...   \n",
       "307506              14707.467773       5.062500e+10         3.638572e+05   \n",
       "307507               6405.097656       5.062500e+10         8.423438e+05   \n",
       "307508               6561.565918       3.422250e+11         2.591068e+06   \n",
       "307509              13358.188477       1.020802e+11         6.915157e+05   \n",
       "307510               5597.068848       4.556250e+11         2.892857e+06   \n",
       "\n",
       "        AMT_GOODS_PRICE EXT_SOURCE_2  AMT_GOODS_PRICE EXT_SOURCE_3  \\\n",
       "0                       92291.750000                  48930.906250   \n",
       "1                      702628.437500                 602804.437500   \n",
       "2                       75080.562500                  98481.445312   \n",
       "3                      193166.015625                 158506.343750   \n",
       "4                      165572.750000                 273783.687500   \n",
       "...                              ...                           ...   \n",
       "307506                 153369.140625                 120080.562500   \n",
       "307507                  26092.529297                 120080.562500   \n",
       "307508                 313352.062500                 128040.164062   \n",
       "307509                 164274.171875                 211231.937500   \n",
       "307510                 478234.875000                  76918.031250   \n",
       "\n",
       "        EXT_SOURCE_3^2  \n",
       "0             0.019434  \n",
       "1             0.284827  \n",
       "2             0.532159  \n",
       "3             0.284827  \n",
       "4             0.284827  \n",
       "...                ...  \n",
       "307506        0.284827  \n",
       "307507        0.284827  \n",
       "307508        0.047905  \n",
       "307509        0.437097  \n",
       "307510        0.012985  \n",
       "\n",
       "[307511 rows x 11 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上記表の10位までの特徴量を抽出\n",
    "features_extract = feature_importances[feature_importances['importance'] >= 0.28]\n",
    "\n",
    "train_ext = train[features_extract['feature']]\n",
    "test_ext = test[features_extract['feature']]\n",
    "\n",
    "train_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameをndarrayに変換\n",
    "X = np.array(train_ext)\n",
    "y = np.array(target)\n",
    "\n",
    "# ホールドアウト法を関数化\n",
    "def holdout_validate(model, test_size=0.25):\n",
    "    # データを分割\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "    # 標準化\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_val_std = scaler.transform(X_val)\n",
    "    \n",
    "    # 学習・推定\n",
    "    model.fit(X_train_std, y_train)\n",
    "    pred = model.predict_proba(X_val_std)\n",
    "    \n",
    "    return roc_auc_score(y_val, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量を抽出したベースモデルのAUC ROC値：0.711301\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=5000)\n",
    "\n",
    "score = holdout_validate(lr)\n",
    "\n",
    "summary['Default']['Holdout'] = score\n",
    "\n",
    "print(\"特徴量を抽出したベースモデルのAUC ROC値：{:5f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### KFold交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [ 61503  61504  61505 ... 307508 307509 307510]\n",
      " Val SET: [    0     1     2 ... 61500 61501 61502]\n",
      "TRAIN SET: [     0      1      2 ... 307508 307509 307510]\n",
      " Val SET: [ 61503  61504  61505 ... 123002 123003 123004]\n",
      "TRAIN SET: [     0      1      2 ... 307508 307509 307510]\n",
      " Val SET: [123005 123006 123007 ... 184504 184505 184506]\n",
      "TRAIN SET: [     0      1      2 ... 307508 307509 307510]\n",
      " Val SET: [184507 184508 184509 ... 246006 246007 246008]\n",
      "TRAIN SET: [     0      1      2 ... 246006 246007 246008]\n",
      " Val SET: [246009 246010 246011 ... 307508 307509 307510]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# KFoldを実施\n",
    "kf = KFold()\n",
    "\n",
    "# 分割されたデータのインデックスを表示\n",
    "for train, val in kf.split(X):\n",
    "    print(\"TRAIN SET: {}\\n Val SET: {}\".format(train, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold分割されたデータをを予測する関数を作成\n",
    "def cross_validate(model, split_size=4):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    \n",
    "    for train_id, val_id in kf.split(X, y):\n",
    "        train_X = X[train_id]\n",
    "        train_y = y[train_id]\n",
    "        val_X = X[val_id]\n",
    "        val_y = y[val_id]\n",
    "        \n",
    "        # 標準化\n",
    "        scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "        train_std = scaler.fit_transform(train_X)\n",
    "        val_std = scaler.transform(val_X)\n",
    "\n",
    "        # 学習、推定\n",
    "        model.fit(train_std, train_y)\n",
    "        pred = model.predict_proba(val_std)\n",
    "        \n",
    "        results.append(roc_auc_score(val_y, pred[:,1]))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressionの交差検証平均：0.714714\n",
      "学習・推定にかかった時間：35.566313 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "result = cross_validate(lr).mean()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Logistic Regressionの交差検証平均：{:5f}\".format(result))\n",
    "print(\"学習・推定にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionの交差検証結果：[0.71424229 0.7081932  0.71190598 0.71122861]\n",
      "平均：0.711393\n",
      "学習・推定にかかった時間：19.452269 sec\n"
     ]
    }
   ],
   "source": [
    "# cross_val_scoreを使用\n",
    "# 標準化を行うため、Pipelineを併用\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_lr = Pipeline([('scaler', QuantileTransformer(output_distribution='normal')),\n",
    "                        ('clf', LogisticRegression(max_iter=5000))])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "score = cross_val_score(pipeline_lr, X, y, scoring='roc_auc', cv=4)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "summary['Default']['Kfold'] = score.mean()\n",
    "\n",
    "print(\"LogisticRegressionの交差検証結果：{}\".format(score))\n",
    "print(\"平均：{:5f}\".format(score.mean()))\n",
    "print(\"学習・推定にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】グリッドサーチ\n",
    "これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになります。機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。最適なパラメータを探していくことを**パラメータチューニング**と呼びます。パラメータチューニングをある程度自動化する単純な方法としては**グリッドサーチ**があります。<br>\n",
    "<br>\n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。<br>\n",
    "<br>\n",
    "[sklearn.model_selection.GridSearchCV — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)<br>\n",
    "<br>\n",
    "GridSearchCVクラスには引数としてモデル、探索範囲、さらにクロスバリデーションを何分割で行うかを与えます。クロスバリデーションの機能も含まれているため、これを使用する場合はKFoldクラスを利用する必要はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### グリッドサーチ\n",
    ">グリッドサーチにて探索したハイパーパラメータを実装したモデルを検証。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 0.01, 'clf__penalty': 'none'}\n",
      "Best score: 0.7115211582186709\n",
      "探索・学習・推定にかかった時間：356.706152 sec\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegressionのハイパーパラメータチューニング\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline_lr = Pipeline([('scaler', QuantileTransformer(output_distribution='normal')),\n",
    "                        ('clf', LogisticRegression(max_iter=5000))])\n",
    "\n",
    "# LogisticRegressionのparameter gridを設定\n",
    "param_grid = { \n",
    "    'clf__penalty': ['none', 'l2'],\n",
    "    'clf__C': [10**i for i in range(-4,4)]\n",
    "}\n",
    "\n",
    "# Grid search実施\n",
    "start = time.time()\n",
    "grid_search = GridSearchCV(pipeline_lr, param_grid, cv=4, scoring='roc_auc')\n",
    "grid_search.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print(\"探索・学習・推定にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チューニング後のvalidation ROC AUC値：0.711516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証用データに対するチューニング後のROC AUC値：0.713966\n"
     ]
    }
   ],
   "source": [
    "# grid searchで得られたハイパーパラメータを設定\n",
    "lr_grid = LogisticRegression(C=0.01, penalty='none', max_iter=5000)\n",
    "\n",
    "pipe_lr_grid = Pipeline([('scaler', QuantileTransformer(output_distribution='normal')),\n",
    "                          ('clf', lr_grid)])\n",
    "\n",
    "score = cross_val_score(pipe_lr_tuned, X, y, scoring='roc_auc', cv=4).mean()b\n",
    "\n",
    "summary['Grid']['Kfold'] = score\n",
    "\n",
    "print(\"チューニング後のvalidation ROC AUC値：{:5f}\".format(score))\n",
    "\n",
    "pipe_lr_tuned.fit(X_train, y_train)\n",
    "pipe_lr_tuned_pred = pipe_lr_tuned.predict_proba(X_val)\n",
    "\n",
    "print(\"検証用データに対するチューニング後のROC AUC値：{:5f}\".\n",
    "      format(roc_auc_score(y_val, pipe_lr_tuned_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チューニング後のholdout ROC AUC値：0.709846\n"
     ]
    }
   ],
   "source": [
    "# ホールドアウト法のスコアも検証\n",
    "score = holdout_validate(lr_grid)\n",
    "summary['Grid']['Holdout'] = score\n",
    "print(\"チューニング後のholdout ROC AUC値：{:5f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Kaggle Notebooksからの調査\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regressionのハイパーパラメータを調査\n",
    "- 層化シャッフル分割交差検証を実装\n",
    "- random search実装\n",
    "- bayesian optimization実装\n",
    "- 別の分類器を試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regressionの仕組みを改めて理解する<br>\n",
    "[Qiita - ロジスティック回帰の初歩を理解する](https://qiita.com/iwashi-kun/items/030ed4dc48b16ca1b5a1)<br>\n",
    "<br>\n",
    "パラメータについて調査<br>\n",
    "[Don’t Sweat the Solver Stuff](https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451)<br>\n",
    "[Discussion - Stack Overflow](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions/52388406#52388406)<br>\n",
    "<br>\n",
    "様々なcross validation手法について<br>\n",
    "[交差検証（cross validation／クロスバリデーション）の種類を整理してみた](https://aizine.ai/cross-validation0910/#toc9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】高い汎化性能のモデル作成\n",
    "問題3で見つけたアイデアと、独自のアイデアを組み合わせ高い汎化性能のモデル作りを進めてください。<br>\n",
    "<br>\n",
    "その過程として、何を行うことで、クロスバリデーションの結果がどの程度変化したかを表にまとめてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 層化シャッフル分割交差検証\n",
    ">KFoldでの交差検証は時間がかかりすぎることが判明。また、このHome Creditデータはクラスが不均衡なため、別の交差検証手法を採用。時間短縮を図ったShuffleSplit、および不均衡に対応するためのStratifiedKFoldを合わせたStratifiedShuffleSplitを採用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層化シャッフル分割交差検証を読み込む\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n",
      "TRAIN sample size: 276759\n",
      " VAL sample size: 30752\n"
     ]
    }
   ],
   "source": [
    "# 分割されたデータのインデックスを表示\n",
    "for train, val in sss.split(X, y):\n",
    "    print(\"TRAIN sample size: {}\\n VAL sample size: {}\".format(len(train), len(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層化シャッフル分割分割されたデータを検証する関数を作成\n",
    "\n",
    "def sss_cross_validate(model, split_size=4):\n",
    "    results = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=split_size)\n",
    "    \n",
    "    for train_id, val_id in sss.split(X, y):\n",
    "        train_X = X[train_id]\n",
    "        train_y = y[train_id]\n",
    "        val_X = X[val_id]\n",
    "        val_y = y[val_id]\n",
    "        \n",
    "        # 標準化\n",
    "        scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "        train_std = scaler.fit_transform(train_X)\n",
    "        val_std = scaler.transform(val_X)\n",
    "        \n",
    "        # 学習、推定\n",
    "        model.fit(train_std, train_y)\n",
    "        pred = model.predict_proba(val_std)\n",
    "        \n",
    "        results.append(roc_auc_score(val_y, pred[:,1]))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressionの層化シャッフル分割交差検証平均：0.712477\n",
      "学習・推定にかかった時間：20.752684 sec\n"
     ]
    }
   ],
   "source": [
    "# 層化シャッフル分割のスコアを検証\n",
    "start = time.time()\n",
    "\n",
    "score = sss_cross_validate(lr_grid).mean()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "summary['Grid']['SSS'] = score\n",
    "\n",
    "print(\"Logistic Regressionの層化シャッフル分割交差検証平均：{:5f}\".format(score))\n",
    "print(\"学習・推定にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "デフォルトパラメータ＋層化シャッフル分割交差検証平均：0.708310\n"
     ]
    }
   ],
   "source": [
    "# デフォルトパラメータの場合も検証\n",
    "score = sss_cross_validate(lr).mean()\n",
    "\n",
    "summary['Default']['SSS'] = score\n",
    "print(\"デフォルトパラメータ＋層化シャッフル分割交差検証平均：{:5f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Random Search\n",
    ">Random Searchによる最適パラメータ探索を実装。Grid Searchとの違いを検証。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__solver': 'liblinear', 'clf__penalty': 'l1', 'clf__C': 100}\n",
      "探索・学習・推定にかかった時間：375.993986 sec\n"
     ]
    }
   ],
   "source": [
    "# Random Searchでハイパーパラメータを探索\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__C': [10**i for i in range(-4,4)],\n",
    "    'clf__solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "rand_search = RandomizedSearchCV(pipeline_lr, param_grid, n_iter=10, cv=4,\n",
    "                                 n_jobs=-1, scoring='roc_auc')\n",
    "rand_search.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "print('Best parameters: {}'.format(rand_search.best_params_))\n",
    "print(\"探索・学習・推定にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Searchパラメータ＋ホールドアウト分割交差検証平均：0.711193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Searchパラメータ＋層化シャッフル分割交差検証平均：0.710201\n",
      "Random Searchパラメータ＋KFold分割交差検証平均：0.711378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchのスコア\n",
    "lr_rand = LogisticRegression(solver='liblinear', penalty='l1', C=100, max_iter=5000)\n",
    "pipe_lr_rand = Pipeline([('scaler', QuantileTransformer(output_distribution='normal')),\n",
    "                          ('clf', lr_rand)])\n",
    "\n",
    "score_randh = holdout_validate(lr_rand)\n",
    "summary['Random']['Holdout'] = score_randh\n",
    "print(\"Random Searchパラメータ＋ホールドアウト分割交差検証平均：{:5f}\".format(score_randh))\n",
    "\n",
    "score_rands = sss_cross_validate(lr_rand).mean()\n",
    "summary['Random']['SSS'] = score_rands\n",
    "print(\"Random Searchパラメータ＋層化シャッフル分割交差検証平均：{:5f}\".format(score_rands))\n",
    "\n",
    "score_randk = cross_val_score(pipe_lr_rand, X, y, scoring='roc_auc', cv=4).mean()\n",
    "summary['Random']['Kfold'] = score_randk\n",
    "print(\"Random Searchパラメータ＋KFold分割交差検証平均：{:5f}\".format(score_randk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Bayesian Optimization\n",
    ">Bayesian最適化はGridやRandom Searchのように無作為にパラメータを選んで検証するのではなく、イテレーション毎に最も高かったスコアのパラメータ組み合わせを参照し、パラメータを微調整する。ここではhyperoptライブラリを使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [17:36<1:13:08, 132.98s/trial, best loss: 0.2878330416557766]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [34:15<13:22, 38.23s/trial, best loss: 0.2878330416557766]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [54:49<00:00, 65.79s/trial, best loss: 0.2878089898036611]   \n",
      "Best params {'C': 1.650775575860084, 'class_weight': 1, 'fit_intercept': 0, 'solver': 1, 'warm_start': 1}\n",
      "探索にかかった時間：3289.646760 sec\n"
     ]
    }
   ],
   "source": [
    "# hyperopt実装\n",
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "\n",
    "hyperopt_params = {\n",
    "    'C': hp.loguniform('C', -4, 4),\n",
    "    'warm_start': hp.choice('warm_start', [True, False]),\n",
    "    'solver': hp.choice('solver', ['liblinear', 'lbfgs', 'saga']),\n",
    "    'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
    "}\n",
    "\n",
    "\n",
    "def objective(params, X=X, y=y, cv=4):\n",
    "    # モデルのインスタンス化\n",
    "    classifier = LogisticRegression(**params, max_iter=5000)\n",
    "    # cross validationを計算\n",
    "    scores = cross_validate(classifier)\n",
    "    # scoresの平均値を取得\n",
    "    score = scores.mean()\n",
    "    # roc aucを最大化したいので、1から引いた値を出力\n",
    "    loss = 1 - score\n",
    "    return loss\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "n_iter = 50\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "          space=hyperopt_params, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=n_iter, \n",
    "          trials=trials,\n",
    "          verbose=1\n",
    "         )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Best params {}\".format(best))\n",
    "print(\"探索にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Searchパラメータ＋ホールドアウト分割交差検証平均：0.714919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Searchパラメータ＋KFold分割交差検証平均：0.712109\n",
      "Bayesian Searchパラメータ＋層化シャッフル分割交差検証平均：0.709537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimizationで得られたハイパーパラメータを設定\n",
    "lr_bayes = LogisticRegression(C=1.650775575860084, warm_start=False, fit_intercept=True, class_weight='balanced', solver='lbfgs', max_iter=5000)\n",
    "\n",
    "pipe_lr_bayes = Pipeline([('scaler', QuantileTransformer(output_distribution='normal')),\n",
    "                          ('clf', lr_bayes)])\n",
    "\n",
    "score_bayes_h = holdout_validate(lr_bayes)\n",
    "summary['Bayesian']['Holdout'] = score_bayes_h\n",
    "print(\"Bayesian Searchパラメータ＋ホールドアウト分割交差検証平均：{:5f}\".format(score_bayes_h))\n",
    "\n",
    "score_bayes_k = cross_val_score(pipe_lr_bayes, X, y, scoring='roc_auc', cv=4).mean()\n",
    "summary['Bayesian']['Kfold'] = score_bayes_k\n",
    "print(\"Bayesian Searchパラメータ＋KFold分割交差検証平均：{:5f}\".format(score_bayes_k))\n",
    "\n",
    "score_bayes_s = sss_cross_validate(lr_bayes).mean()\n",
    "summary['Bayesian']['SSS'] = score_bayes_s\n",
    "print(\"Bayesian Searchパラメータ＋層化シャッフル分割交差検証平均：{:5f}\".format(score_bayes_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 各手法の成績\n",
    ">ここまでで検証した各手法のスコアを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>Grid</th>\n",
       "      <th>Random</th>\n",
       "      <th>Bayesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Holdout</th>\n",
       "      <td>0.711301</td>\n",
       "      <td>0.709846</td>\n",
       "      <td>0.711193</td>\n",
       "      <td>0.714919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kfold</th>\n",
       "      <td>0.711393</td>\n",
       "      <td>0.711516</td>\n",
       "      <td>0.711378</td>\n",
       "      <td>0.712109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSS</th>\n",
       "      <td>0.70831</td>\n",
       "      <td>0.712477</td>\n",
       "      <td>0.710201</td>\n",
       "      <td>0.709537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Default      Grid    Random  Bayesian\n",
       "Holdout  0.711301  0.709846  0.711193  0.714919\n",
       "Kfold    0.711393  0.711516  0.711378  0.712109\n",
       "SSS       0.70831  0.712477  0.710201  0.709537"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各手法の平均スコアを表示\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">パラメータチューニング手法の中では、Bayesian最適化が最もスコアが高く、最適パラメータを探索する精度が高いことが窺える。また、学習時間もGridやRandom Searchよりも短いため、より多くのパラメータを探索できる。分割手法はHoldoutが最もスコアが高いが、過学習の恐れがあるため、KfoldまたはStratified Shuffle Splitを適用することが望ましい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### lightGBMの検証\n",
    ">分類器をlightGBMに変更し、Bayesian Optimization＋KFold交差検証の学習を調査する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "X = train_ext\n",
    "y = target\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "lgb_train = lgb.Dataset(data=train_X, label=train_y)\n",
    "lgb_val = lgb.Dataset(data=val_X, label=val_y, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベースラインlightGBMのHoldout検証\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\tvalid_0's auc: 0.726042\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.727282\n"
     ]
    }
   ],
   "source": [
    "params = {'task': 'train', 'boosting_type': 'gbdt', \n",
    "          'objective': 'binary', 'metric': 'auc', 'n_estimators':5000}\n",
    "\n",
    "print(\"ベースラインlightGBMのHoldout検証\")\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_val,\n",
    "                  early_stopping_rounds=150, verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/lightgbm/engine.py:502: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベースラインlightGBMの交差検証ベストスコア：0.724505\n"
     ]
    }
   ],
   "source": [
    "lgb_train_cv = lgb.Dataset(data=X, label=y)\n",
    "scores = lgb.cv(params, lgb_train_cv, num_boost_round=5000,\n",
    "                    early_stopping_rounds=150, nfold=4)\n",
    "\n",
    "print(\"ベースラインlightGBMの交差検証ベストスコア：{:5f}\".format(max(scores['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [54:14<00:00, 32.54s/trial, best loss: 0.2735315255959847] \n",
      "Best params {'boosting_type': 0, 'class_weight': 0, 'colsample_by_tree': 0.8011473419486966, 'gdbt_subsample': 0.7792465808431693, 'learning_rate': 0.023940707008353938, 'min_child_samples': 435.0, 'num_leaves': 33.0, 'reg_alpha': 0.340140470130553, 'reg_lambda': 0.07433696526494404, 'subsample_for_bin': 180000.0}\n",
      "探索にかかった時間：3254.222796 sec\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "#                  {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                 {'boosting_type': 'goss', 'subsample': 1.0}\n",
    "                ]),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 151, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X, y)\n",
    "\n",
    "def objective(params, n_folds=4):\n",
    "    \n",
    "    # nested spaceの取得\n",
    "    params['subsample'] = params['boosting_type']['subsample']\n",
    "    boost_type = params['boosting_type']['boosting_type']\n",
    "    del params['boosting_type']\n",
    "    params['boosting_type'] = boost_type\n",
    "    \n",
    "    # 数値型への変換\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['min_child_samples'] = int(params['min_child_samples'])\n",
    "    params['subsample_for_bin'] = int(params['subsample_for_bin'])\n",
    "    \n",
    "    # cross validationを計算\n",
    "    scores = lgb.cv(params, lgb_train, num_boost_round=500,\n",
    "                    early_stopping_rounds=150, nfold=n_folds, metrics='auc')\n",
    "    \n",
    "    # scoresの平均値を取得\n",
    "    best_score = max(scores['auc-mean'])\n",
    "    # roc aucを最大化したいので、1から引いた値を出力\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "n_iter = 100\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "          space=lgb_params, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=n_iter, \n",
    "          trials=trials,\n",
    "          verbose=1\n",
    "         )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Best params {}\".format(best))\n",
    "print(\"探索にかかった時間：{:3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/lightgbm/engine.py:502: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チューニング後lightGBMの交差検証ベストスコア：0.725873\n"
     ]
    }
   ],
   "source": [
    "# チューニングしたモデルの検証\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', \n",
    "          'objective': 'binary', 'metric': 'auc', 'n_estimators':5000,\n",
    "          'class_weight': None, 'colsample_by_tree': 0.6127854826784527, 'gdbt_subsample': 0.9903813589683813,\n",
    "          'learning_rate': 0.010170991958005731, 'min_child_samples': 485, 'num_leaves': 53, \n",
    "          'reg_alpha': 0.9983892325538006, 'reg_lambda': 0.6735746969077508, 'subsample_for_bin': 180000}\n",
    "\n",
    "lgb_train_cv = lgb.Dataset(data=X, label=y)\n",
    "scores = lgb.cv(params, lgb_train_cv, num_boost_round=5000,\n",
    "                    early_stopping_rounds=150, nfold=4)\n",
    "\n",
    "print(\"チューニング後lightGBMの交差検証ベストスコア：{:5f}\".format(max(scores['auc-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">lightGBMはロジスティック回帰より良いスコアを出したが、パラメータチューニングによる改善は見られなかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】最終的なモデルの選定\n",
    "最終的にこれは良いというモデルを選び、推定した結果をKaggleに提出してスコアを確認してください。どういったアイデアを取り入れ、どの程度のスコアになったかを記載してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bayesian最適化で得られたハイパーパラメータを実装したlightGBMを提出用スコアに使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\tvalid_0's auc: 0.724419\n",
      "[400]\tvalid_0's auc: 0.729092\n",
      "[600]\tvalid_0's auc: 0.729959\n",
      "[800]\tvalid_0's auc: 0.73014\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's auc: 0.730205\n"
     ]
    }
   ],
   "source": [
    "# Submission用DF作成\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', \n",
    "          'objective': 'binary', 'metric': 'auc', 'n_estimators':5000,\n",
    "          'class_weight': None, 'colsample_by_tree': 0.6127854826784527, 'gdbt_subsample': 0.9903813589683813,\n",
    "          'learning_rate': 0.010170991958005731, 'min_child_samples': 485, 'num_leaves': 53, \n",
    "          'reg_alpha': 0.9983892325538006, 'reg_lambda': 0.6735746969077508, 'subsample_for_bin': 180000}\n",
    "\n",
    "X = train_ext\n",
    "y = target\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "\n",
    "lgb_train = lgb.Dataset(data=train_X, label=train_y)\n",
    "lgb_val = lgb.Dataset(data=val_X, label=val_y, reference=lgb_train)\n",
    "\n",
    "model_submit = lgb.train(params, lgb_train, valid_sets=lgb_val,\n",
    "                  early_stopping_rounds=150, verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.067804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.122863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.030293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.035472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.107270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>0.037530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>0.048289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>0.093389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>0.071363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.154738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR    TARGET\n",
       "0          100001  0.067804\n",
       "1          100005  0.122863\n",
       "2          100013  0.030293\n",
       "3          100028  0.035472\n",
       "4          100038  0.107270\n",
       "...           ...       ...\n",
       "48739      456221  0.037530\n",
       "48740      456222  0.048289\n",
       "48741      456223  0.093389\n",
       "48742      456224  0.071363\n",
       "48743      456250  0.154738\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_submit = model_submit.predict(test_ext)\n",
    "output = pd.DataFrame({'SK_ID_CURR': sk_id,\n",
    "                       'TARGET': pred_submit})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvに書き込み\n",
    "output.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Kaggle上のスコアは0.70411。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
