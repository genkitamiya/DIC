{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint ディープラーニングフレームワーク2\n",
    "## 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。<br>\n",
    "<br>\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。<br>\n",
    "<br>\n",
    "[models/tutorials at master · tensorflow/models](https://www.tensorflow.org/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">下記ノートブックにて実装<br>\n",
    ">https://github.com/genkitamiya/diveintocode-ml/blob/master/sprint/sprint14_DCGAN_Tutorial.ipynb\n",
    ">おまけ（有名人顔やポケモンを生成）<br>\n",
    ">https://github.com/genkitamiya/diveintocode-ml/blob/master/sprint/sprint14_DCGAN_celeb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】（アドバンス課題）様々な手法を実行\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。<br>\n",
    "<br>\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。<br>\n",
    "<br>\n",
    "[models/research at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/research)<br>\n",
    "<br>\n",
    "[google-research/google-research: Google AI Research](https://github.com/google-research/google-research)<br>\n",
    "<br>\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">feelvosやmaskganが気になったが、卒業課題に時間を充てるため、後日実装したいと思う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 異なるフレームワークへの書き換え\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。<br>\n",
    "<br>\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n",
    "\n",
    "### Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。<br>\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8, activation = tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.6771 - acc: 0.6250 - val_loss: 0.6119 - val_acc: 0.6250\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.5750 - acc: 0.7500 - val_loss: 0.5169 - val_acc: 0.8750\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5148 - acc: 0.7656 - val_loss: 0.4878 - val_acc: 0.9375\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.5149 - acc: 0.7500 - val_loss: 0.4297 - val_acc: 0.8750\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.4109 - acc: 0.8594 - val_loss: 0.3806 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.4096 - acc: 0.8750 - val_loss: 0.3491 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.3514 - acc: 0.8906 - val_loss: 0.3050 - val_acc: 0.8750\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.3199 - acc: 0.9219 - val_loss: 0.3555 - val_acc: 0.8125\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.2963 - acc: 0.9375 - val_loss: 0.2837 - val_acc: 0.9375\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2853 - acc: 0.9062 - val_loss: 0.2176 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.2492 - acc: 0.9531 - val_loss: 0.1919 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.2424 - acc: 0.9375 - val_loss: 0.3562 - val_acc: 0.8125\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.2198 - acc: 0.9531 - val_loss: 0.1925 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.2435 - acc: 0.9062 - val_loss: 0.2538 - val_acc: 0.8750\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1660 - acc: 0.9844 - val_loss: 0.1877 - val_acc: 0.8750\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.2097 - acc: 0.9531 - val_loss: 0.1415 - val_acc: 0.9375\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.1650 - acc: 0.9531 - val_loss: 0.1342 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.1745 - acc: 0.9375 - val_loss: 0.1762 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1644 - acc: 0.9375 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.1627 - acc: 0.9219 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.1347 - acc: 0.9688 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.1303 - acc: 0.9531 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.1376 - acc: 0.9688 - val_loss: 0.0863 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.1188 - acc: 0.9531 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.1913 - acc: 0.9219 - val_loss: 0.0743 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.1360 - acc: 0.9688 - val_loss: 0.0789 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.1340 - acc: 0.9375 - val_loss: 0.0684 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.1476 - acc: 0.9531 - val_loss: 0.0649 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.1046 - acc: 0.9531 - val_loss: 0.0883 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.1178 - acc: 0.9375 - val_loss: 0.1320 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.1997 - acc: 0.8750 - val_loss: 0.0971 - val_acc: 0.9375\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0859 - acc: 0.9844 - val_loss: 0.0667 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.1214 - acc: 0.9531 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.1093 - acc: 0.9531 - val_loss: 0.0938 - val_acc: 0.9375\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.1145 - acc: 0.9688 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.1023 - acc: 0.9688 - val_loss: 0.0494 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1292 - acc: 0.9375 - val_loss: 0.0929 - val_acc: 0.9375\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1490 - acc: 0.9531 - val_loss: 0.2221 - val_acc: 0.8125\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1650 - acc: 0.8906 - val_loss: 0.1276 - val_acc: 0.9375\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1023 - acc: 0.9531 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1208 - acc: 0.9531 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1283 - acc: 0.9375 - val_loss: 0.0460 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0972 - acc: 0.9688 - val_loss: 0.0863 - val_acc: 0.9375\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1164 - acc: 0.9219 - val_loss: 0.0390 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0939 - acc: 0.9531 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0961 - acc: 0.9531 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0940 - acc: 0.9688 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0754 - acc: 0.9844 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1703 - acc: 0.9219 - val_loss: 0.1375 - val_acc: 0.9375\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1580 - acc: 0.9375 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "wall time: 3.7440sec\n",
      "\n",
      "Test loss: 0.5241312980651855\n",
      "Test accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "print('wall time: {:.4f}sec'.format(end-start))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルをone-hotに変換\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(8, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 1.2364 - acc: 0.3646 - val_loss: 1.0464 - val_acc: 0.3750\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.0360 - acc: 0.3750 - val_loss: 0.9854 - val_acc: 0.4583\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.9494 - acc: 0.6562 - val_loss: 0.8966 - val_acc: 0.7083\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.8507 - acc: 0.6875 - val_loss: 0.7753 - val_acc: 0.7083\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.7120 - acc: 0.7188 - val_loss: 0.6662 - val_acc: 0.7500\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6110 - acc: 0.7917 - val_loss: 0.5617 - val_acc: 0.9167\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.4938 - acc: 0.9167 - val_loss: 0.4646 - val_acc: 0.7083\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.4014 - acc: 0.8854 - val_loss: 0.3923 - val_acc: 0.9167\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.3286 - acc: 0.9167 - val_loss: 0.3066 - val_acc: 0.9167\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2819 - acc: 0.9167 - val_loss: 0.3184 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.1926 - acc: 0.9583 - val_loss: 0.2647 - val_acc: 0.9167\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.1618 - acc: 0.9271 - val_loss: 0.2223 - val_acc: 0.9167\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1350 - acc: 0.9583 - val_loss: 0.4133 - val_acc: 0.7500\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1879 - acc: 0.9062 - val_loss: 0.2596 - val_acc: 0.9167\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1573 - acc: 0.9271 - val_loss: 0.2736 - val_acc: 0.8333\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1518 - acc: 0.9271 - val_loss: 0.1814 - val_acc: 0.9167\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0821 - acc: 0.9688 - val_loss: 0.2049 - val_acc: 0.9167\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0938 - acc: 0.9688 - val_loss: 0.1701 - val_acc: 0.9583\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0989 - acc: 0.9688 - val_loss: 0.3547 - val_acc: 0.9167\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0838 - acc: 0.9688 - val_loss: 0.1617 - val_acc: 0.9167\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0911 - acc: 0.9583 - val_loss: 0.1758 - val_acc: 0.9167\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0695 - acc: 0.9688 - val_loss: 0.1675 - val_acc: 0.9167\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0796 - acc: 0.9688 - val_loss: 0.1950 - val_acc: 0.9167\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0572 - acc: 0.9792 - val_loss: 0.1594 - val_acc: 0.9583\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0612 - acc: 0.9792 - val_loss: 0.2332 - val_acc: 0.9167\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0651 - acc: 0.9688 - val_loss: 0.1972 - val_acc: 0.9167\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0616 - acc: 0.9688 - val_loss: 0.1984 - val_acc: 0.9167\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0615 - acc: 0.9583 - val_loss: 0.1636 - val_acc: 0.9167\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.1355 - acc: 0.9375 - val_loss: 0.2137 - val_acc: 0.8750\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.1587 - acc: 0.9167 - val_loss: 0.2380 - val_acc: 0.9167\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0593 - acc: 0.9688 - val_loss: 0.2822 - val_acc: 0.9167\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0725 - acc: 0.9688 - val_loss: 0.1621 - val_acc: 0.9583\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0579 - acc: 0.9688 - val_loss: 0.2235 - val_acc: 0.9167\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0676 - acc: 0.9479 - val_loss: 0.1859 - val_acc: 0.9167\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0576 - acc: 0.9688 - val_loss: 0.1647 - val_acc: 0.9167\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.1229 - acc: 0.9479 - val_loss: 0.1940 - val_acc: 0.9167\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1203 - acc: 0.9688 - val_loss: 0.3139 - val_acc: 0.9167\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0605 - acc: 0.9688 - val_loss: 0.1891 - val_acc: 0.9167\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0807 - acc: 0.9688 - val_loss: 0.1583 - val_acc: 0.9167\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1110 - acc: 0.9479 - val_loss: 0.4971 - val_acc: 0.8750\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1036 - acc: 0.9583 - val_loss: 0.1885 - val_acc: 0.8333\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0709 - acc: 0.9479 - val_loss: 0.2240 - val_acc: 0.9167\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0468 - acc: 0.9896 - val_loss: 0.1664 - val_acc: 0.9167\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0746 - acc: 0.9583 - val_loss: 0.1828 - val_acc: 0.9167\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1118 - acc: 0.9375 - val_loss: 0.4149 - val_acc: 0.9167\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1128 - acc: 0.9688 - val_loss: 0.1693 - val_acc: 0.8750\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0620 - acc: 0.9792 - val_loss: 0.2089 - val_acc: 0.9167\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0451 - acc: 0.9792 - val_loss: 0.2098 - val_acc: 0.9167\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0439 - acc: 0.9792 - val_loss: 0.2054 - val_acc: 0.9167\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0412 - acc: 0.9896 - val_loss: 0.2032 - val_acc: 0.9167\n",
      "wall time: 1.3298sec\n",
      "\n",
      "Test loss: 0.02391156740486622\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "print('wall time: {:.4f}sec'.format(end-start))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "house_data = pd.read_csv('/Users/tamiyagt/Documents/machine learning/02_Kaggle/house prices/train.csv')\n",
    "\n",
    "#GrLivArea、YearBuilt、SalePriceを抽出\n",
    "train = house_data.loc[:, ['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
    "\n",
    "# DataFrameをndarrayに変換\n",
    "X = np.array(train.iloc[:, :-1])\n",
    "y = np.array(train.iloc[:, -1])[:,None]\n",
    "\n",
    "# 特徴量を標準化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# 目的変数を対数変換\n",
    "y = np.log1p(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(2,))\n",
    "\n",
    "l = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "l = tf.keras.layers.Dense(10, activation=tf.nn.relu)(l)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.relu)(l)\n",
    "\n",
    "model = tf.keras.Model(input_data, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 37.5427 - mean_squared_error: 37.5427 - val_loss: 2.6651 - val_mean_squared_error: 2.6651\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.4639 - mean_squared_error: 1.4639 - val_loss: 0.4946 - val_mean_squared_error: 0.4946\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.2051 - val_mean_squared_error: 0.2051\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.1806 - mean_squared_error: 0.1806 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.1111 - mean_squared_error: 0.1111 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0901 - mean_squared_error: 0.0901 - val_loss: 0.0565 - val_mean_squared_error: 0.0565\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0711 - mean_squared_error: 0.0711 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0648 - mean_squared_error: 0.0648 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0623 - mean_squared_error: 0.0623 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0617 - mean_squared_error: 0.0617 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0597 - mean_squared_error: 0.0597 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0542 - mean_squared_error: 0.0542 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0620 - mean_squared_error: 0.0620 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0594 - mean_squared_error: 0.0594 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0553 - mean_squared_error: 0.0553 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0543 - mean_squared_error: 0.0543 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0568 - mean_squared_error: 0.0568 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0624 - mean_squared_error: 0.0624 - val_loss: 0.1168 - val_mean_squared_error: 0.1168\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0559 - mean_squared_error: 0.0559 - val_loss: 0.0682 - val_mean_squared_error: 0.0682\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0578 - mean_squared_error: 0.0578 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0537 - mean_squared_error: 0.0537 - val_loss: 0.0715 - val_mean_squared_error: 0.0715\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0606 - mean_squared_error: 0.0606 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0533 - mean_squared_error: 0.0533 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0691 - mean_squared_error: 0.0691 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0561 - mean_squared_error: 0.0561 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0751 - mean_squared_error: 0.0751 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0603 - mean_squared_error: 0.0603 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0574 - mean_squared_error: 0.0574 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0589 - mean_squared_error: 0.0589 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0605 - mean_squared_error: 0.0605 - val_loss: 0.1068 - val_mean_squared_error: 0.1068\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0565 - mean_squared_error: 0.0565 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0582 - mean_squared_error: 0.0582 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0668 - mean_squared_error: 0.0668 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0735 - mean_squared_error: 0.0735 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0730 - mean_squared_error: 0.0730 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0535 - mean_squared_error: 0.0535 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0559 - mean_squared_error: 0.0559 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0630 - mean_squared_error: 0.0630 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0630 - mean_squared_error: 0.0630 - val_loss: 0.1569 - val_mean_squared_error: 0.1569\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0671 - mean_squared_error: 0.0671 - val_loss: 0.0547 - val_mean_squared_error: 0.0547\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0733 - mean_squared_error: 0.0733 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0705 - mean_squared_error: 0.0705 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0669 - mean_squared_error: 0.0669 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0610 - mean_squared_error: 0.0610 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0599 - mean_squared_error: 0.0599 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0595 - mean_squared_error: 0.0595 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "wall time: 4.5817sec\n",
      "\n",
      "Test loss: 0.08127802610397339\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['mse'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "print('wall time: {:.4f}sec'.format(end-start))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTest loss:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#《データセットをダウンロードするコード》\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train[:,:,:,None]  # NHWC\n",
    "X_test = X_test[:,:,:,None]  # NHWC\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# trainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 9, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1450      \n",
      "=================================================================\n",
      "Total params: 2,698\n",
      "Trainable params: 2,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(28,28,1))  # channels last\n",
    "\n",
    "l = tf.keras.layers.Conv2D(8, (3,3), padding='valid', activation=tf.nn.relu)(input_data)\n",
    "l = tf.keras.layers.MaxPool2D((3,3), padding='same')(l)\n",
    "l = tf.keras.layers.Conv2D(16, (3,3), padding='valid', activation=tf.nn.relu)(l)\n",
    "l = tf.keras.layers.MaxPool2D((3,3), padding='same')(l)\n",
    "l = tf.keras.layers.Flatten()(l)\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(l)\n",
    "\n",
    "model = tf.keras.Model(input_data, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      " - 8s - loss: 0.0966 - acc: 0.9714 - val_loss: 0.0817 - val_acc: 0.9742\n",
      "Epoch 2/20\n",
      " - 8s - loss: 0.0931 - acc: 0.9724 - val_loss: 0.0861 - val_acc: 0.9739\n",
      "Epoch 3/20\n",
      " - 9s - loss: 0.0854 - acc: 0.9745 - val_loss: 0.0876 - val_acc: 0.9731\n",
      "Epoch 4/20\n",
      " - 9s - loss: 0.0861 - acc: 0.9748 - val_loss: 0.1036 - val_acc: 0.9721\n",
      "Epoch 5/20\n",
      " - 9s - loss: 0.0862 - acc: 0.9748 - val_loss: 0.1384 - val_acc: 0.9617\n",
      "Epoch 6/20\n",
      " - 8s - loss: 0.0858 - acc: 0.9751 - val_loss: 0.1065 - val_acc: 0.9704\n",
      "Epoch 7/20\n",
      " - 8s - loss: 0.0834 - acc: 0.9767 - val_loss: 0.0957 - val_acc: 0.9744\n",
      "Epoch 8/20\n",
      " - 8s - loss: 0.0847 - acc: 0.9760 - val_loss: 0.0826 - val_acc: 0.9762\n",
      "Epoch 9/20\n",
      " - 9s - loss: 0.0831 - acc: 0.9768 - val_loss: 0.1042 - val_acc: 0.9707\n",
      "Epoch 10/20\n",
      " - 8s - loss: 0.0850 - acc: 0.9769 - val_loss: 0.1008 - val_acc: 0.9738\n",
      "Epoch 11/20\n",
      " - 9s - loss: 0.0847 - acc: 0.9769 - val_loss: 0.1409 - val_acc: 0.9702\n",
      "Epoch 12/20\n",
      " - 9s - loss: 0.0832 - acc: 0.9767 - val_loss: 0.1395 - val_acc: 0.9643\n",
      "Epoch 13/20\n",
      " - 8s - loss: 0.0838 - acc: 0.9774 - val_loss: 0.1178 - val_acc: 0.9691\n",
      "Epoch 14/20\n",
      " - 8s - loss: 0.0834 - acc: 0.9772 - val_loss: 0.0934 - val_acc: 0.9753\n",
      "Epoch 15/20\n",
      " - 8s - loss: 0.0834 - acc: 0.9776 - val_loss: 0.1084 - val_acc: 0.9706\n",
      "Epoch 16/20\n",
      " - 9s - loss: 0.0828 - acc: 0.9768 - val_loss: 0.1094 - val_acc: 0.9702\n",
      "Epoch 17/20\n",
      " - 8s - loss: 0.0820 - acc: 0.9769 - val_loss: 0.0968 - val_acc: 0.9763\n",
      "Epoch 18/20\n",
      " - 8s - loss: 0.0856 - acc: 0.9773 - val_loss: 0.1041 - val_acc: 0.9714\n",
      "Epoch 19/20\n",
      " - 9s - loss: 0.0834 - acc: 0.9767 - val_loss: 0.0922 - val_acc: 0.9711\n",
      "Epoch 20/20\n",
      " - 8s - loss: 0.0835 - acc: 0.9760 - val_loss: 0.0962 - val_acc: 0.9740\n",
      "wall time: 170.7776sec\n",
      "\n",
      "Test loss: 0.08520193512865516\n",
      "Test accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=20,\n",
    "                    epochs=20,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "end = time.time()\n",
    "print('wall time: {:.4f}sec'.format(end-start))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">下記ノートブックにて実装<br>\n",
    ">https://github.com/genkitamiya/diveintocode-ml/blob/master/sprint/sprint14_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）フレームワークの比較\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。<br>\n",
    "<br>\n",
    "**《視点例》**\n",
    "- 計算速度\n",
    "- コードの行数・可読性\n",
    "- 用意されている機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- 計算速度：各分類を同モデル・条件で実行したところ、MNIST以外においては、PyTorchの計算速度がKerasより早かった。より複雑なモデルの場合はKerasに軍配が上がるのだろうか？<br>\n",
    ">- コードの行数・可読性：行数はKerasが圧倒的に少ない。また、可読性についてもKerasが見やすいと思われる。ただし、モデルの透過性はより細かなコードが必要な分、PyTorchが優れている。<br>\n",
    ">- 用意されている機能：同フレームワーク共に機能が備わっていると思われるが、上記の通り、PyTorchの方が小回りが効いており、より複雑なモデルやカスタマイズに適している（例：並列層の実装など）<br>\n",
    ">\n",
    ">\n",
    ">その他、下記の相違点を確認：<br>\n",
    ">**Keras/Tensorflow**<br>\n",
    ">- input NHWC\n",
    ">- onehot encoding必須\n",
    ">- Module/Functional型搭載<br>\n",
    ">\n",
    ">\n",
    ">**PyTorch**<br>\n",
    ">- input NCHW\n",
    ">- onehot 不要\n",
    ">- 各レイヤーのサイズ指定が必要\n",
    ">- Module/Functional型搭載\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
