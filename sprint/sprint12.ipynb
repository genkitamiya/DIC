{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク2\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。<br>\n",
    "<br>\n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。<br>\n",
    "\n",
    "### データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。<br>\n",
    "<br>\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。<br>\n",
    "<br>\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。<br>\n",
    "<br>\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "$i$ : 配列の行方向のインデックス\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "$F_{h}, F_{w}$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "全てスカラーです。<br>\n",
    "<br>\n",
    "<br>\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "\n",
    "$$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_{m}}$ : $b_{m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "勾配 $\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ や $\\frac{\\partial L}{\\partial b_{m}}$ を求めるためのバックプロパゲーションの数式が以下である。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "ただし、 $i-s<0$ または $i-s>N_{out,h}-1$ または $j-t<0$ または $j-t>N_{out,w}-1$ のとき $\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$ です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### テプリッツ行列を活用<br>\n",
    ">![im1](https://i.stack.imgur.com/FlUZU.png) * ![im2](https://i.stack.imgur.com/eOP5R.png)<br>\n",
    ">![im3](https://i.stack.imgur.com/yLd8G.png)<br>\n",
    ">![im4](https://i.stack.imgur.com/oMhJs.png)<br>\n",
    "><br>\n",
    ">参考：\n",
    ">- [Stack Overflow](https://stackoverflow.com/questions/16798888/2-d-convolution-as-a-matrix-matrix-multiplication)\n",
    ">- [Convolutions and Backpropagations](https://medium.com/@pavisj/convolutions-and-backpropagations-46026a8f5d2c)\n",
    ">- [Backpropagation in a convolutional layer](https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509)\n",
    ">- [Wikipedia - Toeplitz Matrix](https://en.wikipedia.org/wiki/Toeplitz_matrix#Discrete_convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1フィルタ分の出力を計算\n",
    "def convolve(X, k):\n",
    "    # テプリッツ用wを生成\n",
    "    pad_h = int(X.shape[-2] - k.shape[-2])  # kの高さをXに合わせる\n",
    "    pad_w = int(X.shape[-1] - k.shape[-1])  # kの幅をXに合わせる\n",
    "    k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
    "\n",
    "    # 次元削減\n",
    "    X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW)\n",
    "    k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
    "\n",
    "    # テプリッツ行列用の引数を準備\n",
    "    H, W = X.shape[-2:]\n",
    "    Hf, Wf = k.shape[-2:]\n",
    "    Ho, Wo = output_size((H,W), (Hf,Wf))  # 出力サイズを計算\n",
    "    # 不要な要素行を指定する\n",
    "    idx = np.arange(H * W).reshape(H, W)\n",
    "    del_row = idx[..., :H-Hf, W-Wf+1:].flatten()\n",
    "    # テプリッツの１列目\n",
    "    first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  \n",
    "    # テプリッツの１行目\n",
    "    first_row = k_flat  \n",
    "\n",
    "    # テプリッツ行列を生成（不要行は削除）\n",
    "    toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
    "    \n",
    "    # フィルタ毎に行列をブロック化し、縦に再結合\n",
    "    toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW)\n",
    "\n",
    "    # 行列演算\n",
    "    output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
    "\n",
    "    return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    2D Convolution結合\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルタのサイズ\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    A_ : 次の形のndarray, shape (N, F, Ho, Wo)\n",
    "      畳み込み出力\n",
    "    dZ_ : 次の形のndarray, shape (N, C, H, W)\n",
    "      逆伝播入力に対するdZ勾配\n",
    "    dw_ : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "      逆伝播入力に対するdw勾配\n",
    "    db_ : 次の形のndarray, shape (F)\n",
    "      逆伝播入力に対するdb勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.A_ = None\n",
    "        self.dZ_ = None\n",
    "        self.dw_ = None\n",
    "        self.db_ = None\n",
    "        \n",
    "    def forward(self, Z, w, b):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (N, C, H, W)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          ある層の重み\n",
    "        b : 次の形のndarray, shape (F)\n",
    "          ある層のバイアス\n",
    "        \"\"\"\n",
    "        \n",
    "        self.A_ = self._convolve(Z, w) + b.reshape(1, len(b), 1, 1)  # A(N,F,Ho,Wo)\n",
    "        \n",
    "        return self.A_\n",
    "    \n",
    "    \n",
    "    def backward(self, Z, w, dA):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (N, C, H, W)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          ある層の重み\n",
    "        dA : 次の形のndarray, shape (N, F, Ho, Wo)\n",
    "          ある層に逆伝播されたAに関するLoss勾配\n",
    "        \"\"\"        \n",
    "        \n",
    "        # dZ計算\n",
    "        # チャンネル毎に演算を行うため、行列を転置（NとCを残す）\n",
    "        w_ = np.transpose(w, (1,0,2,3))  # w(F,C,Hf,Wf) → w(C,F,Hf,Wf)\n",
    "        w_ = np.flip(w_)  # 上下左右に反転\n",
    "        # dAをpadding処理\n",
    "        pad_h = len(w[-2]) - 1\n",
    "        pad_w = len(w[-1]) - 1\n",
    "        dA_ = np.pad(dA, [(0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)])  # HoWo次元のみpadding\n",
    "        self.dZ_ = self._convolve(dA_, w_)  # dZ(N,C,H,W)\n",
    "        \n",
    "        \n",
    "        # dw計算            \n",
    "        # フィルタ毎に演算を行うため、行列を転置（FとCを残す）\n",
    "        Z_ = np.transpose(Z, (1,0,2,3))  # Z(N,C,H,W) → Z(C,N,H,W)\n",
    "        dA_ = np.transpose(dA, (1,0,2,3))  # dA(N,F,Ho,Wo) → dA(F,N,Ho,Wo)\n",
    "        self.dw_ = np.transpose(self._convolve(Z_, dA_), (1,0,2,3))  # dw(C,F,Hf,Wf) → dw(F,C,Hf,Wf)\n",
    "        \n",
    "        \n",
    "        # db計算 \n",
    "        # F以外の次元の和をとる\n",
    "        self.db_ = np.sum(dA, axis=(0,2,3))  # db(F)\n",
    "        \n",
    "        return self.dZ_, self.dw_, self.db_\n",
    "    \n",
    "    \n",
    "    def _output_size(self, HW, HfWf, P=0, S=1):\n",
    "    \n",
    "        HoWo = (np.array(HW) + 2*P - np.array(HfWf)) / S + 1\n",
    "        \n",
    "        return HoWo.astype('int')\n",
    "    \n",
    "    def _convolve(self, X, k):\n",
    "        \"\"\"\n",
    "        巡回演算\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H, W)\n",
    "          巡回される行列\n",
    "        k : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          巡回する行列\n",
    "        \"\"\"\n",
    "        # テプリッツ用wを生成\n",
    "        pad_h = int(X.shape[-2] - k.shape[-2])  # kの高さをXに合わせる\n",
    "        pad_w = int(X.shape[-1] - k.shape[-1])  # kの幅をXに合わせる\n",
    "        k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
    "\n",
    "        # 次元削減\n",
    "        X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW) --[1]\n",
    "        k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
    "\n",
    "        # テプリッツ行列用の引数を準備\n",
    "        Ho, Wo = output_size(X.shape[-2:], k.shape[-2:])  # 出力サイズを計算\n",
    "        # 不要な要素行を指定する\n",
    "        i = k.shape[-1] - 1\n",
    "        j = X.shape[-2] - k.shape[-2]\n",
    "        del_row = []\n",
    "        for i in range(i):\n",
    "            del_row.extend(np.arange(i+j+1, X.shape[-2]*j+i+1, X.shape[-2]).astype(list)) \n",
    "        # テプリッツの１列目\n",
    "        first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  \n",
    "        # テプリッツの１行目\n",
    "        first_row = k_flat  \n",
    "\n",
    "        # テプリッツ行列を生成（不要行は削除）\n",
    "        toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
    "\n",
    "        # フィルタ毎に行列をブロック化し、縦に再結合\n",
    "        toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW) --[2]\n",
    "\n",
    "        # 行列演算（[2]*[1].T）\n",
    "        output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
    "\n",
    "        return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "$h$ が高さ方向、 $w$ が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size(HW, HfWf, P=0, S=1):\n",
    "    \n",
    "    # 引数を全てndarrayに変換\n",
    "    HW = np.array(HW); HfWf = np.array(HfWf); P = np.array(P); S = np.array(S)\n",
    "    \n",
    "    # ブロードキャストでHo,Woを算出\n",
    "    HoWo = (HW + 2*P - HfWf) / S + 1\n",
    "\n",
    "    return HoWo.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size((5,5), (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_{h}×S_{w}$ の範囲内の行（p）と列（q）\n",
    "\n",
    "$S_{h}, S_{w}$ : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値<br>\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。<br>\n",
    "<br>\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス $(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考<br>\n",
    "> [Stack Overflow](https://stackoverflow.com/questions/42463172/how-to-perform-max-mean-pooling-on-a-2d-array-using-numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, fsize):\n",
    "        self.fsize = fsize\n",
    "        self.X_shape = None\n",
    "        self.rot_shape = None\n",
    "        self.screen = None\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        H, W = X.shape[-2:]\n",
    "        Hf, Wf = self.fsize\n",
    "        \n",
    "            \n",
    "        Ho = H // Hf\n",
    "        Wo = W // Wf\n",
    "\n",
    "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
    "\n",
    "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
    "#         pool = np.nanmax(X_pad.reshape(self.screen), axis=(-1,-3))  # Max値取得のためだけなら早い\n",
    "        \n",
    "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
    "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
    "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
    "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
    "        \n",
    "        pool = np.nanmax(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
    "        \n",
    "        # 逆伝播用Mask行列を用意\n",
    "        self.mask = (X_2d == pool.reshape(-1,1))\n",
    "\n",
    "        return pool, X_2d, X_rot\n",
    "        \n",
    "    def backward(self, dX):\n",
    "\n",
    "        # 配列をMaskと同じ２次元に落とす\n",
    "        dpool = np.where(self.mask, dX.reshape(-1,1), 0)  # mask適用\n",
    "\n",
    "        # 元の形に戻す\n",
    "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
    "        \n",
    "        return dpool.reshape(self.X_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】（アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。<br>\n",
    "<br>\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。<br>\n",
    "<br>\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPool2d:\n",
    "\n",
    "    def __init__(self, fsize):\n",
    "        self.fsize = fsize\n",
    "        self.X_shape = None\n",
    "        self.rot_shape = None\n",
    "        self.screen = None\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        H, W = X.shape[-2:]\n",
    "        Hf, Wf = self.fsize\n",
    "        \n",
    "            \n",
    "        Ho = H // Hf\n",
    "        Wo = W // Wf\n",
    "\n",
    "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
    "\n",
    "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
    "        \n",
    "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
    "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
    "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
    "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
    "        \n",
    "        pool = np.nanmean(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
    "        \n",
    "        # 逆伝播用Mask行列を用意\n",
    "        self.mask = np.zeros(X_2d.shape)\n",
    "\n",
    "        return pool\n",
    "        \n",
    "    def backward(self, dX):\n",
    "\n",
    "        # 配列をMaskと同じ２次元に落とす\n",
    "        dpool = dX.reshape(-1,1) + self.mask  # 平均値を各poolに振り分ける\n",
    "\n",
    "        # 元の形に戻す\n",
    "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
    "        \n",
    "        return dpool.reshape(self.X_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。<br>\n",
    "<br>\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。<br>\n",
    "<br>\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.shape = X.shape\n",
    "        \n",
    "        return X.reshape(self.shape[0], np.prod(self.shape[1:]))  # X(N,C,H,W) → X(N,CHW)\n",
    "    \n",
    "    def backward(self, dX):\n",
    "        \n",
    "        return dX.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。<br>\n",
    "<br>\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def update_dw(self, layer, grad):\n",
    "        \"\"\"\n",
    "        ある層の重み勾配を渡す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer: object instance\n",
    "          ある層のインスタンス\n",
    "        grad : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "          重みの勾配\n",
    "        \"\"\"\n",
    "        return grad / layer.input.shape[0]\n",
    "    \n",
    "    def update_db(self, layer, grad):\n",
    "        \"\"\"\n",
    "        ある層のバイアス勾配を渡す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer: object instance\n",
    "          ある層のインスタンス\n",
    "        grad : 次の形のndarray, shape (n_nodes_self, )\n",
    "          バイアスの勾配\n",
    "        \"\"\"\n",
    "        return grad / layer.input.shape[0]\n",
    "        \n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    AdaGradによる確率的勾配降下法\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Hw : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "      ある層のイテレーション毎の重み勾配の二乗和\n",
    "    Hb : 次の形のndarray, shape (n_nodes_self, )\n",
    "      ある層のイテレーション毎のバイアス勾配の二乗和\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Hw = 1e-8\n",
    "        self.Hb = 1e-8\n",
    "        \n",
    "    def update_dw(self, layer, grad):\n",
    "        \"\"\"\n",
    "        ある層の重み勾配を渡す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer: object instance\n",
    "          ある層のインスタンス\n",
    "        grad : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "          重みの勾配\n",
    "        \"\"\"\n",
    "        self.Hw += (grad/layer.input.shape[0])**2\n",
    "        grad *= (1/np.sqrt(self.Hw)) / layer.input.shape[0]\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def update_db(self, layer, grad):\n",
    "        \"\"\"\n",
    "        ある層のバイアス勾配を渡す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer: object instance\n",
    "          ある層のインスタンス\n",
    "        grad : 次の形のndarray, shape (n_nodes_self, )\n",
    "          バイアスの勾配\n",
    "        \"\"\"\n",
    "        self.Hb += (grad/layer.input.shape[0])**2\n",
    "        grad *= (1/np.sqrt(self.Hb)) / layer.input.shape[0]\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "        \n",
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    2D Convolution結合\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_size : int\n",
    "      フィルタのサイズ\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    A_ : 次の形のndarray, shape (N, F, Ho, Wo)\n",
    "      畳み込み出力\n",
    "    dZ_ : 次の形のndarray, shape (N, C, H, W)\n",
    "      逆伝播入力に対するdZ勾配\n",
    "    dw_ : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "      逆伝播入力に対するdw勾配\n",
    "    db_ : 次の形のndarray, shape (F)\n",
    "      逆伝播入力に対するdb勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.A_ = None\n",
    "        self.dZ_ = None\n",
    "        self.dw_ = None\n",
    "        self.db_ = None\n",
    "        \n",
    "    def forward(self, Z, w, b):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (N, C, H, W)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          ある層の重み\n",
    "        b : 次の形のndarray, shape (F)\n",
    "          ある層のバイアス\n",
    "        \"\"\"\n",
    "        \n",
    "        self.A_ = self._convolve(Z, w) + b.reshape(1, len(b), 1, 1)  # A(N,F,Ho,Wo)\n",
    "        \n",
    "        return self.A_\n",
    "    \n",
    "    \n",
    "    def backward(self, Z, w, dA):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (N, C, H, W)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          ある層の重み\n",
    "        dA : 次の形のndarray, shape (N, F, Ho, Wo)\n",
    "          ある層に逆伝播されたAに関するLoss勾配\n",
    "        \"\"\"        \n",
    "        \n",
    "        # dZ計算\n",
    "        # チャンネル毎に演算を行うため、行列を転置（NとCを残す）\n",
    "        w_ = np.transpose(w, (1,0,2,3))  # w(F,C,Hf,Wf) → w(C,F,Hf,Wf)\n",
    "        w_ = np.flip(w_)  # 上下左右に反転\n",
    "        # dAをpadding処理\n",
    "        pad_h = w.shape[-2] - 1\n",
    "        pad_w = w.shape[-1] - 1\n",
    "        dA_ = np.pad(dA, [(0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)])  # HoWo次元のみpadding\n",
    "        self.dZ_ = self._convolve(dA_, w_)  # dZ(N,C,H,W)\n",
    "        \n",
    "        \n",
    "        # dw計算            \n",
    "        # フィルタ毎に演算を行うため、行列を転置（FとCを残す）\n",
    "        Z_ = np.transpose(Z, (1,0,2,3))  # Z(N,C,H,W) → Z(C,N,H,W)\n",
    "        dA_ = np.transpose(dA, (1,0,2,3))  # dA(N,F,Ho,Hw) → dA(F,N,Ho,Wo)\n",
    "        self.dw_ = np.transpose(self._convolve(Z_, dA_), (1,0,2,3))  # dw(C,F,Hf,Wf) → dw(F,C,Hf,Wf)\n",
    "\n",
    "        \n",
    "        # db計算 \n",
    "        # F以外の次元の和をとる\n",
    "        self.db_ = np.sum(dA, axis=(0,2,3))  # db(F)\n",
    "        \n",
    "        return self.dZ_, self.dw_, self.db_\n",
    "    \n",
    "    \n",
    "    def _output_size(self, HW, HfWf, P=0, S=1):\n",
    "    \n",
    "        # 引数を全てndarrayに変換\n",
    "        HW = np.array(HW); HfWf = np.array(HfWf); P = np.array(P); S = np.array(S)\n",
    "\n",
    "        # ブロードキャストでHo,Woを算出\n",
    "        HoWo = (HW + 2*P - HfWf) / S + 1   \n",
    "        \n",
    "        return HoWo.astype('int')\n",
    "    \n",
    "    \n",
    "    def _convolve(self, X, k):\n",
    "        \"\"\"\n",
    "        巡回演算\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H, W)\n",
    "          巡回される行列\n",
    "        k : 次の形のndarray, shape (F, C, Hf, Wf)\n",
    "          巡回する行列\n",
    "        \"\"\"\n",
    "        H, W = X.shape[-2:]\n",
    "        Hf, Wf = k.shape[-2:]\n",
    "        Ho, Wo = output_size((H,W), (Hf,Wf)) \n",
    "        \n",
    "        # テプリッツ用wを生成\n",
    "        pad_h = int(H - Hf)  # kの高さをXに合わせる\n",
    "        pad_w = int(W - Wf)  # kの幅をXに合わせる\n",
    "        k_pad = np.pad(k, [(0,0), (0,0), (0, pad_h), (0, pad_w)])  # k(F,C,H,W)\n",
    "\n",
    "        # 次元削減\n",
    "        X_flat = np.transpose(X, (0, 2, 1, 3)).reshape(len(X), -1)  # X(N,C,H,W) → X(N,HCW)\n",
    "        k_flat = np.transpose(k_pad, (0, 2, 1, 3)).flatten()  # k(F,C,H,W) → k(FHCW)\n",
    "\n",
    "        # テプリッツ行列用の引数を準備\n",
    "        idx = np.arange(H * W).reshape(H, W)  # feature mapと同サイズのインデックス配列を生成\n",
    "        del_row = idx[..., :H-Hf, W-Wf+1:].flatten()  # 不要な要素行を指定する\n",
    "        first_col = np.r_[k_flat[0], np.zeros(Ho*Wo + len(del_row) - 1)]  # テプリッツの１列目\n",
    "        first_row = k_flat  # テプリッツの１行目  \n",
    "\n",
    "        # テプリッツ行列を生成（不要行は削除）\n",
    "        toep = np.delete(linalg.toeplitz(first_col, first_row), del_row, axis=0)  # toep(HoWo,FHCW)\n",
    "\n",
    "        # フィルタ毎に行列をブロック化し、縦に再結合\n",
    "        toep_reorder = np.vstack(np.split(toep, len(k), axis=1))  #toep(FHoWo,HCW)\n",
    "\n",
    "        # 行列演算\n",
    "        output = toep_reorder@X_flat.T  # out(FHoWo,N)\n",
    "\n",
    "        return output.T.reshape(len(X), len(k), Ho, Wo)  # out(N,F,Ho,Wo)\n",
    "\n",
    "        \n",
    "class Affine:\n",
    "    \"\"\"\n",
    "    線形結合\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      順伝播の出力\n",
    "    dZ_ : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
    "      逆伝播入力に対するdZ勾配\n",
    "    dw_ : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "      逆伝播入力に対するdw勾配\n",
    "    db_ : 次の形のndarray, shape (n_nodes_self, )\n",
    "      逆伝播入力に対するdb勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.A_ = None\n",
    "        self.dZ_ = None\n",
    "        self.dw_ = None\n",
    "        self.db_ = None\n",
    "        \n",
    "    def forward(self, Z, w, b):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "          ある層の重み\n",
    "        b : 次の形のndarray, shape (n_nodes_self, )\n",
    "          ある層のバイアス\n",
    "        \"\"\"\n",
    "        self.A_ = Z @ w + b\n",
    "        \n",
    "        return self.A_\n",
    "    \n",
    "    def backward(self, Z, w, dA):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "          ある層の重み\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に逆伝播されたAに関するLoss勾配\n",
    "        \"\"\"\n",
    "        self.dZ_ = dA @ w.T\n",
    "        self.dw_ = Z.T @ dA\n",
    "        self.db_ = np.sum(dA, axis=0)\n",
    "        \n",
    "        return self.dZ_, self.dw_, self.db_\n",
    "\n",
    "        \n",
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    シグモイド関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      順伝播の出力\n",
    "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      逆伝播入力に対するdA勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z_ = None\n",
    "        self.dA_ = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        self.Z_ = 1 / (1+np.exp(-A))\n",
    "        \n",
    "        return self.Z_\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に逆伝播されたZに関するLoss勾配\n",
    "        \"\"\"\n",
    "        self.dA_ = dZ * ((1 - self.Z_) * self.Z_)\n",
    "    \n",
    "        return self.dA_\n",
    "        \n",
    "        \n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパーボリックタンジェント関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      順伝播の出力\n",
    "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      逆伝播入力に対するdA勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z_ = None\n",
    "        self.dA_ = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        self.Z_ = np.tanh(A)\n",
    "        \n",
    "        return self.Z_\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に逆伝播されたZに関するLoss勾配\n",
    "        \"\"\"\n",
    "        self.dA_ = dZ * (1 - self.Z_**2)\n",
    "        \n",
    "        return self.dA_\n",
    "        \n",
    "        \n",
    "class ReLu:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        ReLu関数\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          順伝播の出力\n",
    "        dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          逆伝播入力に対するdA勾配\n",
    "        \"\"\"\n",
    "        self.Z_ = None\n",
    "        self.dA_ = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        self.Z_ = np.maximum(A, 0)\n",
    "        \n",
    "        return self.Z_\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に逆伝播されたZに関するLoss勾配\n",
    "        \"\"\"\n",
    "        self.dA_ = dZ * np.where(self.Z_ > 0, 1, 0)\n",
    "        \n",
    "        return self.dA_\n",
    "    \n",
    "        \n",
    "class Pool2d:\n",
    " \n",
    "    def __init__(self, fsize, alg='MAX'):\n",
    "        self.fsize = fsize\n",
    "        self.alg = alg\n",
    "        self.X_shape = None\n",
    "        self.rot_shape = None\n",
    "        self.screen = None\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        H, W = X.shape[-2:]\n",
    "        Hf, Wf = self.fsize\n",
    "        \n",
    "       \n",
    "        Ho = H // Hf\n",
    "        Wo = W // Wf\n",
    "\n",
    "        X_pad = X[..., :Ho*Hf, :Wo*Wf]\n",
    "\n",
    "        self.screen = X.shape[:-2] + (Ho, Hf, Wo, Wf)  # 6次元\n",
    "#         pool = np.nanmax(X_pad.reshape(self.screen), axis=(-1,-3))  # Max値取得のためだけなら早い\n",
    "        \n",
    "        # 配列をフィルタ毎に再配置し（上下反転後、90度転回）、２次元に落とす\n",
    "        X_rot = np.flip(np.rot90(X_pad.reshape(self.screen), axes=(3,4)), axis=3)\n",
    "        X_2d = X_rot.reshape(-1, Hf*Wf)\n",
    "        self.rot_shape = X_rot.shape  # 逆伝播用にshapeを保存\n",
    "        \n",
    "        if self.alg == 'MAX':\n",
    "            pool = np.nanmax(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
    "            # 逆伝播用Mask行列を用意\n",
    "            self.mask = (X_2d == pool.reshape(-1,1))\n",
    "            \n",
    "        if self.alg == 'MEAN':\n",
    "            pool = np.nanmean(X_2d, axis=1).reshape(X.shape[:-2] + (Ho, Wo)) \n",
    "            # 逆伝播用Mask行列を用意\n",
    "            self.mask = np.zeros(X_2d.shape)\n",
    "\n",
    "        return pool\n",
    "        \n",
    "    def backward(self, dX):\n",
    "\n",
    "        # 配列をMaskと同じ２次元に落とす\n",
    "        if self.alg == 'MAX':\n",
    "            dpool = np.where(self.mask, dX.reshape(-1,1), 0)  # mask適用\n",
    "        if self.alg == 'MEAN':\n",
    "            dpool = dX.reshape(-1,1) + self.mask  # 平均値を各poolに振り分ける\n",
    "\n",
    "        # 元の形に戻す\n",
    "        dpool = np.rot90(np.flip(dpool.reshape(self.rot_shape), axis=3), k=3, axes=(3,4))\n",
    "        \n",
    "        return dpool.reshape(self.X_shape)\n",
    "    \n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    SoftMax関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Z_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      順伝播の出力\n",
    "    dA_ : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      逆伝播入力に対するdA勾配\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z_ = None\n",
    "        self.dA_ = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          ある層に順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        # オーバーフロー対策として定数を引き算する\n",
    "        C = np.max(A)\n",
    "        self.Z_ = np.exp(A - C) / np.sum(np.exp(A - C), axis=1)[:, None]\n",
    "        \n",
    "        return self.Z_\n",
    "    \n",
    "    def backward(self, y):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "          正解ラベルデータ\n",
    "        \"\"\"\n",
    "        self.dA_ = self.Z_ - y\n",
    "        \n",
    "        return self.dA_\n",
    "                    \n",
    "\n",
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.shape = X.shape\n",
    "        \n",
    "        return X.reshape(self.shape[0], np.prod(self.shape[1:]))  # X(N,C,H,W) → X(N,CHW)\n",
    "    \n",
    "    def backward(self, dX):\n",
    "        \n",
    "        return dX.reshape(self.shape)\n",
    "\n",
    "        \n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, shape_self):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (shape_self)\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.standard_normal(shape_self)\n",
    "        return W\n",
    "    \n",
    "    def B(self, shape_self):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (n_nodes_self, )\n",
    "        \"\"\"\n",
    "        B = np.random.randn(n_nodes_self)\n",
    "        return B\n",
    "    \n",
    "\n",
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    ザビエルの初期値によるシンプルな初期化\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    \n",
    "    def W(self, n_nodes_prev, shape_self):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes_prev : int\n",
    "          前の層のノード数\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (shape_self)\n",
    "        \"\"\"\n",
    "        self.sigma = 1 / np.sqrt(np.prod(n_nodes_prev))\n",
    "        \n",
    "        W = self.sigma * np.random.standard_normal(shape_self)  # tupleを引数にできるstandard_normalを使用\n",
    "        return W\n",
    "    \n",
    "    def B(self, shape_self):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (shape_self)\n",
    "        \"\"\"\n",
    "        B = np.random.standard_normal(shape_self)\n",
    "        return B\n",
    "    \n",
    "    \n",
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    フーの初期値によるシンプルな初期化\n",
    "    Attributes\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "        \n",
    "    def W(self, n_nodes_prev, shape_self):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes_prev : int\n",
    "          前の層のノード数\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (shape_self)\n",
    "        \"\"\"\n",
    "        self.sigma = np.sqrt(2/np.prod(n_nodes_prev))\n",
    "        \n",
    "        W = self.sigma * np.random.standard_normal(shape_self)  # tupleを引数にできるstandard_normalを使用\n",
    "        return W\n",
    "    \n",
    "    def B(self, shape_self):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape_self : 次の形のndarray, shape (shape_self)\n",
    "          自身の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (shape_self)\n",
    "        \"\"\"\n",
    "        B = np.random.standard_normal(shape_self)\n",
    "        return B\n",
    "    \n",
    "    \n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    \n",
    "    \n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    層の生成\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    combination : object instance\n",
    "      結合関数インスタンス\n",
    "    activation : object instance\n",
    "      活性化関数インスタンス\n",
    "    initializer : object instance\n",
    "      初期化方法のインスタンス\n",
    "    optimizer : object instance\n",
    "      最適化手法のインスタンス\n",
    "    n_nodes_prev : int\n",
    "      前の層のノード数\n",
    "    n_nodes_self : int\n",
    "      自身の層のノード数\n",
    "      \n",
    "    Attributes\n",
    "    ----------\n",
    "    w : 次の形のndarray, shape (n_nodes_prev, n_nodes_self)\n",
    "      重みパラメータ\n",
    "    b : 次の形のndarray, shape (n_nodes_self, )\n",
    "      バイアスパラメータ\n",
    "    input : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
    "      入力データ\n",
    "    output : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "      出力データ\n",
    "    prev : object instance\n",
    "      前の層\n",
    "    next : object instance\n",
    "      後の層\n",
    "    \"\"\"\n",
    "    def __init__(self, combination, activation, \n",
    "                 initializer=None, optimizer=None, n_nodes_prev=None, w_shape=None, b_shape=None):\n",
    "        self.comb = combination\n",
    "        self.activ = activation\n",
    "        self.initializer = initializer # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes_prev = n_nodes_prev\n",
    "        self.w_shape = w_shape\n",
    "        self.b_shape = b_shape\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "        \n",
    "        if self.initializer:\n",
    "            self.w = self.initializer.W(self.n_nodes_prev, self.w_shape)\n",
    "            self.b = self.initializer.B(self.b_shape)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes_prev)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        if self.comb:\n",
    "            A = self.comb.forward(X, self.w, self.b)\n",
    "            Z = self.activ.forward(A)\n",
    "\n",
    "        else:\n",
    "            Z = self.activ.forward(X)\n",
    "        \n",
    "        self.input = X\n",
    "        self.output = Z\n",
    "        \n",
    "        if self.next:\n",
    "            return self.next.forward(Z)\n",
    "        else:\n",
    "            return Z\n",
    "    \n",
    "    def backward(self, y, lr):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_nodes_self)\n",
    "            後ろから流れてきた勾配\n",
    "        lr : float\n",
    "          学習率\n",
    "        \"\"\"\n",
    "        if self.comb:\n",
    "            dA = self.activ.backward(y)\n",
    "            dZ, dw, db = self.comb.backward(self.input, self.w, dA)\n",
    "            \n",
    "            # パラメータ更新\n",
    "            self.w -= lr * self.optimizer.update_dw(self, dw)\n",
    "            self.b -= lr * self.optimizer.update_db(self, db)\n",
    "            \n",
    "        else:\n",
    "            dZ = self.activ.backward(y)\n",
    "\n",
    "        \n",
    "        if self.prev:\n",
    "            self.prev.backward(dZ, lr)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "class ScratchConvNeuralNetworkClassifier:\n",
    "    \"\"\"\n",
    "    可変層畳み込みニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    layers : list\n",
    "      ネットワークに組み込まれる層のリスト\n",
    "    epoch : int\n",
    "      エポック数\n",
    "    sigma : float\n",
    "      初期パラメータ用（SimpleInitializerのみ適用）\n",
    "    batch_size : int\n",
    "      ミニバッチのサンプル数\n",
    "    verbose : bool\n",
    "      学習経過の出力\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    loss_train : list\n",
    "      訓練データに対するLoss\n",
    "    loss_val : list\n",
    "      検証データに対するLoss\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, epoch=100, sigma=0.1, lr=0.01, batch_size=100, verbose=False, **kwargs):\n",
    "        self.layers = layers\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "        # レイヤー同士を結合\n",
    "        for i, layer in enumerate(layers): \n",
    "            if i == 0:\n",
    "                layer.next = self.layers[i+1]\n",
    "            elif layer == layers[-1]:\n",
    "                layer.prev = self.layers[i-1] \n",
    "            else:\n",
    "                layer.next = self.layers[i+1]\n",
    "                layer.prev = self.layers[i-1]\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, n_classes)\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, n_classes)\n",
    "            検証データの正解値\n",
    "        \"\"\"  \n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "            \n",
    "            get_mini_batch_t = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            \n",
    "            times = []\n",
    "            start = time.time()\n",
    "            \n",
    "            # 各mini batchの損失をリスト化\n",
    "            loss_batch_t = []\n",
    "            \n",
    "            for X_mini, y_mini in get_mini_batch_t:\n",
    "\n",
    "                # 順伝播\n",
    "                output = self.layers[0].forward(X_mini)\n",
    "                # 逆伝播\n",
    "                self.layers[-1].backward(y_mini, self.lr)\n",
    "\n",
    "                loss_batch_t.append(self.cross_entropy(output, y_mini))\n",
    "            \n",
    "            # 各epochの平均損失をselfに格納\n",
    "            loss_train = np.mean(loss_batch_t)\n",
    "            self.loss_train.append(loss_train)\n",
    "            \n",
    "            \n",
    "            # 検証データの推定\n",
    "            if hasattr(X_val, '__array__') and hasattr(y_val, '__array__'):\n",
    "                \n",
    "                batch_size_v = int(self.batch_size * len(X_val)/len(X))\n",
    "                get_mini_batch_v = GetMiniBatch(X_val, y_val, batch_size=batch_size_v)\n",
    "                loss_batch_v = []\n",
    "\n",
    "                for X_mini, y_mini in get_mini_batch_v:\n",
    "                    \n",
    "                    output = self.layers[0].forward(X_mini)\n",
    "                \n",
    "                    loss_batch_v.append(self.cross_entropy(output, y_mini))\n",
    "            \n",
    "                # 各epochの平均損失をselfに格納\n",
    "                loss_val = np.mean(loss_batch_v)\n",
    "                self.loss_val.append(loss_val)\n",
    "\n",
    "            end = time.time()\n",
    "            times.append(end-start)\n",
    "\n",
    "            # 学習経過の出力\n",
    "            if self.verbose and (i+1) % 10 == 0:\n",
    "                print(\"Epoch {}; Loss {:.4f}\".format(i+1, loss_train),\n",
    "                      \"  --Avg Epoch Time {:.4f}sec\".format(np.mean(times)))            \n",
    "                   \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          検証用データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, )\n",
    "          推定結果\n",
    "        \"\"\"\n",
    "        output = self.layers[0].forward(X)\n",
    "        \n",
    "        return np.argmax(output, axis=1)\n",
    "        \n",
    "    def cross_entropy(self, X, y):\n",
    "        \"\"\"\n",
    "        クロスエントロピー誤差を計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_features)\n",
    "          入力データ\n",
    "        y : 次の形のndarray, shape (batch_size, n_classes)\n",
    "          入力データの正解ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          float\n",
    "          クロスエントロピー誤差\n",
    "        \"\"\"\n",
    "        return (-1/len(X)) * np.sum((y*np.log(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#《データセットをダウンロードするコード》\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# Xを標準化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# yをone-hot encode\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "# データを分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "# 特徴量を４次元に変換\n",
    "X_train = X_train[:, None, :, :]\n",
    "X_val = X_val[:, None, :, :]\n",
    "X_test = X_test[:, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(model, title='Scratch CNN Loss'):\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(np.arange(len(model.loss_train)), model.loss_train, label='train loss')\n",
    "    plt.plot(np.arange(len(model.loss_val)), model.loss_val, label='val loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Loss 0.4429   --Avg Epoch Time 13.3096sec\n",
      "Epoch 20; Loss 0.3471   --Avg Epoch Time 13.4729sec\n",
      "Epoch 30; Loss 0.3054   --Avg Epoch Time 13.1649sec\n",
      "Epoch 40; Loss 0.2824   --Avg Epoch Time 15.6093sec\n",
      "Epoch 50; Loss 0.2649   --Avg Epoch Time 13.0302sec\n",
      "Epoch 60; Loss 0.2508   --Avg Epoch Time 13.2075sec\n",
      "Epoch 70; Loss 0.2388   --Avg Epoch Time 14.1062sec\n",
      "Epoch 80; Loss 0.2286   --Avg Epoch Time 19.4469sec\n",
      "Epoch 90; Loss 0.2210   --Avg Epoch Time 20.7198sec\n",
      "Epoch 100; Loss 0.2133   --Avg Epoch Time 13.9296sec\n",
      "\n",
      " Accuracy: 0.9327\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5000サンプルで学習\n",
    "\n",
    "# ハイパーパラメータの設定 w(F,C,Hf,Wf) b(F)\n",
    "W1 = np.array((5,1,5,5)); B1 = 5\n",
    "W2 = np.array((320,10)); B2 = 10\n",
    "\n",
    "# 4層のConvネットワーク\n",
    "layer_1 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 784, W1, B1)  # 1,28,28 to 5,24,24\n",
    "layer_2 = Layer(None, Pool2d((3,3))) # 5,24,24 to 5,8,8\n",
    "layer_3 = Layer(None, Flatten())  # 5,8,8 to 320\n",
    "output = Layer(Affine(), Softmax(), XavierInitializer(), AdaGrad(), 320, W2, B2)  # 320 to 10\n",
    "\n",
    "params = {'epoch': 100, \n",
    "          'lr': 0.01,\n",
    "          'batch_size': 200,\n",
    "          }\n",
    "\n",
    "cnn = ScratchConvNeuralNetworkClassifier(layers=[layer_1, layer_2, layer_3, output], verbose=True, **params)\n",
    "\n",
    "cnn.fit(X_train[:5000], y_train[:5000], X_val[:5000], y_val[:5000])\n",
    "\n",
    "pred = cnn.predict(X_test)\n",
    "\n",
    "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "plot_loss(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Loss 0.2513   --Avg Epoch Time 141.0102sec\n",
      "Epoch 20; Loss 0.2135   --Avg Epoch Time 143.0293sec\n",
      "Epoch 30; Loss 0.1977   --Avg Epoch Time 150.8538sec\n",
      "Epoch 40; Loss 0.1880   --Avg Epoch Time 182.0450sec\n",
      "Epoch 50; Loss 0.1816   --Avg Epoch Time 155.6188sec\n",
      "\n",
      " Accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 全てのデータで学習\n",
    "\n",
    "# ハイパーパラメータの設定 w(F,C,Hf,Wf) b(F)\n",
    "W1 = np.array((5,1,5,5)); B1 = 5\n",
    "W2 = np.array((320,10)); B2 = 10\n",
    "\n",
    "# 4層のConvネットワーク\n",
    "layer_1 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 784, W1, B1)  # 1,28,28 to 5,24,24\n",
    "layer_2 = Layer(None, Pool2d((3,3))) # 5,24,24 to 5,8,8\n",
    "layer_3 = Layer(None, Flatten())  # 5,8,8 to 320\n",
    "output = Layer(Affine(), Softmax(), XavierInitializer(), AdaGrad(), 320, W2, B2)  # 320 to 10\n",
    "\n",
    "params = {'epoch': 50, \n",
    "          'lr': 0.01,\n",
    "          'batch_size': 200,\n",
    "          }\n",
    "\n",
    "cnn = ScratchConvNeuralNetworkClassifier(layers=[layer_1, layer_2, layer_3, output], verbose=True, **params)\n",
    "\n",
    "cnn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "pred = cnn.predict(X_test)\n",
    "\n",
    "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "plot_loss(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）LeNet\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。現在では実用的に使われることはありませんが、歴史的に重要なのは1998年の LeNet です。この構造を再現してMNISTに対して動かし、Accuracyを計算してください。<br>\n",
    "<br>\n",
    "[Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)<br>\n",
    "\n",
    "![LeNet](https://t.gyazo.com/teams/diveintocode/83358987a273743a589b9388dfdf59ac.png)\n",
    "\n",
    "※上記論文から引用<br>\n",
    "<br>\n",
    "サブサンプリングとは現在のプーリングに相当するものです。現代風に以下のように作ってみることにします。活性化関数も当時はシグモイド関数ですが、ReLUとします。\n",
    "\n",
    "1. 畳み込み層　出力チャンネル数6、フィルタサイズ5×5、ストライド1\n",
    "2. ReLU\n",
    "3. 最大プーリング\n",
    "4. 畳み込み層　出力チャンネル数16、フィルタサイズ5×5、ストライド1\n",
    "5. ReLU\n",
    "6. 最大プーリング\n",
    "7. 平滑化\n",
    "8. 全結合層　出力ノード数120\n",
    "9. ReLU\n",
    "10. 全結合層　出力ノード数84\n",
    "11. ReLU\n",
    "12. 全結合層　出力ノード数10\n",
    "13. ソフトマックス関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Loss 0.4910   --Avg Epoch Time 298.4082sec\n",
      "Epoch 20; Loss 0.3930   --Avg Epoch Time 204.8978sec\n",
      "Epoch 30; Loss 0.3488   --Avg Epoch Time 255.7060sec\n",
      "Epoch 40; Loss 0.3263   --Avg Epoch Time 204.5032sec\n",
      "Epoch 50; Loss 0.3103   --Avg Epoch Time 177.0646sec\n",
      "\n",
      " Accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ハイパーパラメータの設定 w(F,C,Hf,Wf) b(F)\n",
    "W1 = np.array((6,1,5,5)); B1 = 6\n",
    "W2 = np.array((16,6,5,5)); B2 = 16\n",
    "W3 = np.array((256, 120)); B3 = 120\n",
    "W4 = np.array((120,84)); B4 = 84\n",
    "Wo = np.array((84,10)); Bo = 10\n",
    "\n",
    "# LeNet構造のConvネットワーク\n",
    "layer_1 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 28*28, W1, B1)  # 1,28,28 to 6,24,24\n",
    "layer_2 = Layer(None, Pool2d((2,2))) # 6,24,24 to 6,12,12\n",
    "layer_3 = Layer(Conv2d(), ReLu(), HeInitializer(), AdaGrad(), 6*12*12, W2, B2)  # 6,12,12 to 16,8,8\n",
    "layer_4 = Layer(None, Pool2d((2,2))) # 16,8,8 to 16,4,4\n",
    "layer_5 = Layer(None, Flatten())  # 16,4,4 to 256\n",
    "layer_6 = Layer(Affine(), ReLu(), XavierInitializer(), AdaGrad(), 256, W3, B3)  # 256 to 120\n",
    "layer_7 = Layer(Affine(), ReLu(), XavierInitializer(), AdaGrad(), 120, W4, B4)  # 120 to 84\n",
    "output = Layer(Affine(), Softmax(), XavierInitializer(), AdaGrad(), 84, Wo, Bo)  # 84 to 10\n",
    "\n",
    "params = {'epoch': 50, \n",
    "          'lr': 0.01,\n",
    "          'batch_size': 200,\n",
    "          }\n",
    "\n",
    "cnn = ScratchConvNeuralNetworkClassifier(layers=[layer_1, layer_2, layer_3, layer_4,\n",
    "                                                 layer_5, layer_6, layer_7, output],\n",
    "                                         verbose=True, **params)\n",
    "\n",
    "cnn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "pred = cnn.predict(X_test)\n",
    "\n",
    "print(\"\\n Accuracy: {}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "plot_loss(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）有名な画像認識モデルの調査\n",
    "CNNの代表的な構造としてははAlexNet(2012)、VGG16(2014)などがあります。こういったものはフレームワークで既に用意されていることも多いです。<br>\n",
    "<br>\n",
    "どういったものがあるか簡単に調べてまとめてください。名前だけでも見ておくと良いでしょう。<br>\n",
    "<br>\n",
    "<br>\n",
    "**《参考》**\n",
    "\n",
    "[Applications - Keras Documentation](https://keras.io/ja/applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">AlexNet(2012)<br>\n",
    ">ディープラーニング・ブームの火付け役となったモデル。構造は畳み込み層とプーリング層を重ねたLeNetと変わらないものだが、ReLuを使っている、Local Response Normalization（局所正規化）を行う、Dropoutを採用などといった違いがある。また、初めて学習にGPUが使用されたモデルでもある。<br>\n",
    "><br>\n",
    ">ResNet(2015)<br>\n",
    ">Microsoft Researchによって開発されたResidual Network（ResNet）と呼ばれるモデル。当時のCNNモデルは層数を増やすことによって精度を高められることが知られていたが、同時に単純な層数の増加は勾配消失に繋がるジレンマがあった。ResNetは、手前の層の入力を自身の出力と足し合わせて後ろの層に渡せるShortcut Connectionという機構を導入し、勾配消失を解消した。結果、2015年のILSVRC（画像認識コンペ）では152層のモデルを構築し（2014年以前はせいぜい20層）コンペで優勝した。<br>\n",
    "><br>\n",
    ">Inception(2014) Xception(2016)<br>\n",
    ">Inceptionとその派生であるXceptionは層毎に様々なアーキテクチャ（畳み込みフィルタサイズなど）を探索し、自動で学習するモデル体系である。Inceptionではチャンネル同士の関係性の分離が指摘され、また、計算負荷が高かったため、改良版のXceptionが提案された。Xceptionではまず、チャンネル毎の畳み込みを行い（depthwise convolution）、その後1x1フィルタによる次元畳み込みを行う（pointwise convolution）。これら二つの演算をまとめてdepthwise separable convolutionと呼び、感覚的には2D+1D探索を実装する感じである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】出力サイズとパラメータ数の計算\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。<br>\n",
    "<br>\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。<br>\n",
    "<br>\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。<br>\n",
    "<br>\n",
    "1.\n",
    "- 入力サイズ : 144×144, 3チャンネル\n",
    "- フィルタサイズ : 3×3, 6チャンネル\n",
    "- ストライド : 1\n",
    "- パディング : なし<br>\n",
    ">答案\n",
    ">- 出力サイズ：142x142, 6チャンネル\n",
    ">- パラメータ数：重み 162 (6x3x3x3)；バイアス 6 (6x1x1x1)\n",
    "<br>\n",
    "2.\n",
    "- 入力サイズ : 60×60, 24チャンネル\n",
    "- フィルタサイズ : 3×3, 48チャンネル\n",
    "- ストライド　: 1\n",
    "- パディング : なし<br>\n",
    ">答案\n",
    ">- 出力サイズ：58x58, 48チャンネル\n",
    ">- パラメータ数：重み 10368 (48x3x3x24)；バイアス 48 (48x1x1x1)\n",
    "<br>\n",
    "3.\n",
    "- 入力サイズ : 20×20, 10チャンネル\n",
    "- フィルタサイズ: 3×3, 20チャンネル\n",
    "- ストライド : 2\n",
    "- パディング : なし<br>\n",
    ">答案\n",
    ">- 出力サイズ：9x9, 20チャンネル\n",
    ">- パラメータ数：重み 1800 (20x3x3x10)；バイアス 20 (20x1x1x1)\n",
    "\n",
    "<br>\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題10】（アドバンス課題）フィルタサイズに関する調査\n",
    "畳み込み層にはフィルタサイズというハイパーパラメータがありますが、2次元畳み込み層において現在では3×3と1×1の使用が大半です。以下のそれぞれを調べたり、自分なりに考えて説明してください。\n",
    "\n",
    "- 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "- 高さや幅方向を持たない1×1のフィルタの効果\n",
    ">フィルタサイズはなるべく特徴量を失わないために小さいサイズが好ましいと考えられる。加えて、画像データの場合は、重要な情報は輪郭にあることが多いため、小さいフィルタサイズはこの輪郭情報を漏れなくキャッチできる利点がある。これら理由のため、1x1や3x3が多用されると思われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
