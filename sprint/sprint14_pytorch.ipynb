{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "Kerasで実装したモデル・パラメータと同条件で実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris（2値分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/tamiyagt/Documents/Machine Learning/01_github/diveintocode-ml/sprint/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 入力データはfloat、ラベルはlong（int）に変換\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "test_set = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris_bin(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input=4, n_hidden=8, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.l = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, num_classes),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.l(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.1281\n",
      "Epoch [20/100], Loss: 0.0040\n",
      "Epoch [30/100], Loss: 0.0044\n",
      "Epoch [40/100], Loss: 0.0391\n",
      "Epoch [50/100], Loss: 0.0182\n",
      "Epoch [60/100], Loss: 0.0193\n",
      "Epoch [70/100], Loss: 0.0047\n",
      "Epoch [80/100], Loss: 0.3534\n",
      "Epoch [90/100], Loss: 0.0043\n",
      "Epoch [100/100], Loss: 0.0010\n",
      "test acc: 1.0000\n",
      "\n",
      " wall time: 3.7222sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1587428061935/work/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "model = Iris_bin()\n",
    "N_EPOCHS = 100\n",
    "LR = 0.01\n",
    "N_BATCH = 1\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 学習\n",
    "model.train()\n",
    "train_loader = DataLoader(train_set, batch_size=N_BATCH, shuffle=True)\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for samples, labels in train_loader:\n",
    "\n",
    "        samples = torch.autograd.Variable(samples)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()  # 勾配の初期化\n",
    "        outputs = model(samples)  # 出力計算\n",
    "        loss = criterion(outputs, labels)  # ロス計算\n",
    "        loss.backward()  # 逆伝播\n",
    "        optimizer.step()  # パラメータ更新\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, N_EPOCHS, loss.item()))\n",
    "\n",
    "# 推定\n",
    "total, tp = 0, 0\n",
    "test_loader = DataLoader(test_set, batch_size=N_BATCH, shuffle=False)\n",
    "model.eval()\n",
    "for sample, label in test_loader:\n",
    "    samples = torch.autograd.Variable(samples)\n",
    "    labels = torch.autograd.Variable(labels)\n",
    "\n",
    "    outputs = model(samples)\n",
    "    preds = torch.eq(torch.sign(labels-0.5), torch.sign(outputs-0.5))        \n",
    "    total += label.shape[0]\n",
    "    tp += sum(preds)\n",
    "\n",
    "acc = int(tp/total)\n",
    "end = time.time()\n",
    "\n",
    "print('test acc: {:.4f}'.format(acc))\n",
    "print('\\n wall time: {:.4f}sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris（多値分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/tamiyagt/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/tamiyagt/Documents/Machine Learning/01_github/diveintocode-ml/sprint/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "y = np.array(y).astype(np.int)\n",
    "X = np.array(X)\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 入力データはfloat、ラベルはlong（int）に変換\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "test_set = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris_multi(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input=4, n_hidden1=16, n_hidden2=8, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.l = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.l(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2678\n",
      "Epoch [20/50], Loss: 0.3310\n",
      "Epoch [30/50], Loss: 0.0248\n",
      "Epoch [40/50], Loss: 0.0207\n",
      "Epoch [50/50], Loss: 0.0218\n",
      "test acc: 0.9000\n",
      "\n",
      " wall time: 0.3956sec\n"
     ]
    }
   ],
   "source": [
    "model = Iris_multi()\n",
    "N_EPOCHS = 50\n",
    "LR = 0.01\n",
    "N_BATCH = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 学習\n",
    "model.train()\n",
    "train_loader = DataLoader(train_set, batch_size=N_BATCH, shuffle=True)\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for samples, labels in train_loader:\n",
    "\n",
    "        samples = torch.autograd.Variable(samples)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()  # 勾配の初期化\n",
    "        outputs = model(samples)  # 出力計算\n",
    "        loss = criterion(outputs, labels)  # ロス計算\n",
    "        loss.backward()  # 逆伝播\n",
    "        optimizer.step()  # パラメータ更新\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, N_EPOCHS, loss.item()))\n",
    "\n",
    "# 推定\n",
    "total, tp = 0, 0\n",
    "test_loader = DataLoader(test_set, batch_size=N_BATCH, shuffle=False)\n",
    "model.eval()\n",
    "for samples, labels in test_loader:\n",
    "    samples = torch.autograd.Variable(samples)\n",
    "    labels = torch.autograd.Variable(labels)\n",
    "\n",
    "    outputs = model(samples)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    total += labels.shape[0]\n",
    "    tp += torch.eq(preds, labels).sum().item()\n",
    "\n",
    "acc = tp/total\n",
    "end = time.time()\n",
    "\n",
    "print('test acc: {:.4f}'.format(acc))\n",
    "print('\\n wall time: {:.4f}sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "house_data = pd.read_csv('/Users/tamiyagt/Documents/machine learning/02_Kaggle/house prices/train.csv')\n",
    "\n",
    "#GrLivArea、YearBuilt、SalePriceを抽出\n",
    "train = house_data.loc[:, ['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
    "\n",
    "# DataFrameをndarrayに変換\n",
    "X = np.array(train.iloc[:, :-1])\n",
    "y = np.array(train.iloc[:, -1])[:,None]\n",
    "\n",
    "# 特徴量を標準化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# 目的変数を対数変換\n",
    "y = np.log1p(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# 入力データはfloat、ラベルはlong（int）に変換\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "test_set = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class House_Prices(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input=2, n_hidden1=10, n_hidden2=10, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.l = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, num_classes),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.l(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.0046\n",
      "Epoch [20/50], Loss: 0.0206\n",
      "Epoch [30/50], Loss: 0.0198\n",
      "Epoch [40/50], Loss: 0.0260\n",
      "Epoch [50/50], Loss: 0.0528\n",
      "test MSE: 0.0217\n",
      "\n",
      " wall time: 3.4426sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = House_Prices()\n",
    "N_EPOCHS = 50\n",
    "LR = 0.01\n",
    "N_BATCH = 10\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 学習\n",
    "model.train()\n",
    "train_loader = DataLoader(train_set, batch_size=N_BATCH, shuffle=True)\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for samples, labels in train_loader:\n",
    "\n",
    "        samples = torch.autograd.Variable(samples)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()  # 勾配の初期化\n",
    "        outputs = model(samples)  # 出力計算\n",
    "        loss = criterion(outputs, labels)  # ロス計算\n",
    "        loss.backward()  # 逆伝播\n",
    "        optimizer.step()  # パラメータ更新\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, N_EPOCHS, loss.item()))\n",
    "\n",
    "# 推定\n",
    "total, tp = 0, 0\n",
    "test_loader = DataLoader(test_set, batch_size=N_BATCH, shuffle=False)\n",
    "model.eval()\n",
    "for samples, labels in test_loader:\n",
    "    samples = torch.autograd.Variable(samples)\n",
    "    labels = torch.autograd.Variable(labels)\n",
    "\n",
    "    outputs = model(samples)\n",
    "    \n",
    "    mse = F.mse_loss(outputs, labels)\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print('test MSE: {:.4f}'.format(mse))\n",
    "print('\\n wall time: {:.4f}sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#《データセットをダウンロードするコード》\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train[:,None,:,:]  # NCHW\n",
    "X_test = X_test[:,None,:,:]  # NCHW\n",
    "\n",
    "# trainとvalに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 入力データはfloat、ラベルはlong（int）に変換\n",
    "# PyTorchはonehot encoding不要\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_val, y_val)\n",
    "test_set = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3),\n",
    "            nn.MaxPool2d((3,3), padding=1))\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
    "            nn.MaxPool2d((3,3), padding=1))\n",
    "        self.lo = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(144, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l1(x))\n",
    "        h = F.relu(self.l2(h))\n",
    "        out = self.lo(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0368\n",
      "Epoch [2/20], Loss: 0.0526\n",
      "Epoch [3/20], Loss: 0.0068\n",
      "Epoch [4/20], Loss: 0.0613\n",
      "Epoch [5/20], Loss: 0.0189\n",
      "Epoch [6/20], Loss: 0.6423\n",
      "Epoch [7/20], Loss: 0.0190\n",
      "Epoch [8/20], Loss: 0.0037\n",
      "Epoch [9/20], Loss: 0.0101\n",
      "Epoch [10/20], Loss: 0.0522\n",
      "Epoch [11/20], Loss: 0.1633\n",
      "Epoch [12/20], Loss: 0.1919\n",
      "Epoch [13/20], Loss: 0.1376\n",
      "Epoch [14/20], Loss: 0.0159\n",
      "Epoch [15/20], Loss: 0.0281\n",
      "Epoch [16/20], Loss: 0.0461\n",
      "Epoch [17/20], Loss: 0.0086\n",
      "Epoch [18/20], Loss: 0.0013\n",
      "Epoch [19/20], Loss: 0.0007\n",
      "Epoch [20/20], Loss: 0.0023\n",
      "test acc: 0.9555\n",
      "\n",
      " wall time: 232.8668sec\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "N_EPOCHS = 20\n",
    "LR = 0.01\n",
    "N_BATCH = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "# 学習\n",
    "model.train()\n",
    "train_loader = DataLoader(train_set, batch_size=N_BATCH, shuffle=True)\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for samples, labels in train_loader:\n",
    "\n",
    "        samples = torch.autograd.Variable(samples)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()  # 勾配の初期化\n",
    "        outputs = model(samples)  # 出力計算\n",
    "        loss = criterion(outputs, labels)  # ロス計算\n",
    "        loss.backward()  # 逆伝播\n",
    "        optimizer.step()  # パラメータ更新\n",
    "        \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "          .format(epoch+1, N_EPOCHS, loss.item()))\n",
    "\n",
    "# 推定\n",
    "total, tp = 0, 0\n",
    "test_loader = DataLoader(test_set, batch_size=N_BATCH, shuffle=False)\n",
    "model.eval()\n",
    "for samples, labels in test_loader:\n",
    "    samples = torch.autograd.Variable(samples)\n",
    "    labels = torch.autograd.Variable(labels)\n",
    "\n",
    "    outputs = model(samples)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    total += labels.shape[0]\n",
    "    tp += torch.eq(preds, labels).sum().item()\n",
    "\n",
    "acc = tp/total\n",
    "end = time.time()\n",
    "\n",
    "print('test acc: {:.4f}'.format(acc))\n",
    "print('\\n wall time: {:.4f}sec'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
