{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習\n",
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "- ブレンディング\n",
    "- バギング\n",
    "- スタッキング\n",
    "\n",
    "### 小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。<br>\n",
    "<br>\n",
    "House Prices: Advanced Regression Techniquesのtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。<br>\n",
    "<br>\n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。<br>\n",
    "<br>\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  YearBuilt  SalePrice\n",
       "0       1710       2003     208500\n",
       "1       1262       1976     181500\n",
       "2       1786       2001     223500\n",
       "3       1717       1915     140000\n",
       "4       2198       2000     250000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = pd.read_csv('/Users/tamiyagt/Documents/machine learning/02_Kaggle/house prices/train.csv')\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "#GrLivArea、YearBuilt、SalePriceを抽出\n",
    "train = house_data.loc[:, ['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 2)\n",
      "(1168,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DataFrameをndarrayに変換\n",
    "X = np.array(train.iloc[:, :-1])\n",
    "y = np.array(train.iloc[:, -1])\n",
    "\n",
    "# データの分割（今回は8：2の割合）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検証用関数を作成\n",
    "def cross_validate(model, X, y, split_size=5):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    \n",
    "    for train_id, val_id in kf.split(X, y):\n",
    "        train_X = X[train_id]\n",
    "        train_y = y[train_id]\n",
    "        val_X = X[val_id]\n",
    "        val_y = y[val_id]\n",
    "\n",
    "        # 学習、推定\n",
    "        model.fit(train_X, train_y)\n",
    "        pred = model.predict(val_X)\n",
    "        \n",
    "        results.append(mean_squared_error(val_y, pred))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装\n",
    "**ブレンディング**をスクラッチ実装し、単一モデルより精度があがる例を**最低3つ**示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "### ブレンディングとは\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。<br>\n",
    "\n",
    "- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。<br>\n",
    "<br>\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。<br>\n",
    "<br>\n",
    "**《補足》**<br>\n",
    "<br>\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。<br>\n",
    "[sklearn.ensemble.VotingClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from numpy import random\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blendingクラスの実装\n",
    "\n",
    "class Blending():\n",
    "    def __init__(self, model_list=None):\n",
    "        self.model_list = model_list\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.model_list:\n",
    "            model.fit(X, y)\n",
    "            \n",
    "    def predict(self, X, metric='mean', weight=None):\n",
    "        \n",
    "        preds = np.empty((len(X), len(self.model_list)))\n",
    "        \n",
    "        for i, model in enumerate(self.model_list):\n",
    "            preds[:, i] = model.predict(X)\n",
    "        \n",
    "        \n",
    "        if metric == 'mean':\n",
    "            return preds.mean(axis=1)\n",
    "        elif metric == 'median':\n",
    "            return np.median(preds, axis=1)\n",
    "        elif metric == 'max':\n",
    "            return preds.max(axis=1)\n",
    "        elif metric == 'min':\n",
    "            return preds.min(axis=1)\n",
    "        elif metric == 'weighted':\n",
    "            return np.sum(preds*weight, axis=1) / np.sum(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">《例１》　線形回帰、SVR、決定木をブレンド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 1.72e+09\n",
      "SVR MSE: 5.85e+09\n",
      "Decision Tree MSE: 2.07e+09\n",
      "\n",
      "\n",
      "Blended mean model MSE: 1.99e+09\n",
      "Blended median model MSE: 1.78e+09\n",
      "Blended max model MSE: 2.94e+09\n",
      "Blended min model MSE: 5.00e+09\n"
     ]
    }
   ],
   "source": [
    "# 各モデルをインスタンス化\n",
    "linreg = LinearRegression()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "models = [linreg, svr, tree]\n",
    "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
    "\n",
    "# 各モデルのブレンドモデルをインスタンス化\n",
    "blend = Blending(models)\n",
    "\n",
    "# 各単一モデルの学習・推定\n",
    "for model, label in zip(models, labels):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(\"{} MSE: {:.2e}\".format(label, mean_squared_error(y_test, pred)))\n",
    "print('\\n')\n",
    "\n",
    "# ブレンドモデルの学習・推定\n",
    "metrics = ['mean', 'median', 'max', 'min']\n",
    "\n",
    "for metric in metrics:\n",
    "    blend.fit(X_train, y_train)\n",
    "    pred = blend.predict(X_test, metric=metric)\n",
    "    print(\"Blended {} model MSE: {:.2e}\".format(metric, mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">デフォルトパラメータのモデル３種を４種のブレンド法で推定。中央値を求めたブレンドが最もMSEが低い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">《例２》　標準化し、モデルをブレンド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 各モデルをインスタンス化\n",
    "linreg = LinearRegression()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "models = [linreg, svr, tree]\n",
    "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
    "\n",
    "# 各モデルのブレンドモデルをインスタンス化\n",
    "blend = Blending(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.0455\n",
      "SVR MSE: 0.0465\n",
      "Decision Tree MSE: 0.0808\n",
      "\n",
      "\n",
      "Blended mean model MSE: 0.0484\n",
      "Blended median model MSE: 0.0458\n",
      "Blended max model MSE: 0.0558\n",
      "Blended min model MSE: 0.0724\n"
     ]
    }
   ],
   "source": [
    "# 特徴量を標準化\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# 目的変数を対数変換\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# 各単一モデルの学習・推定\n",
    "for model, label in zip(models, labels):\n",
    "    model.fit(X_train_std, y_train_log)\n",
    "    pred = model.predict(X_test_std)\n",
    "    print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# ブレンドモデルの学習・推定\n",
    "metrics = ['mean', 'median', 'max', 'min']\n",
    "\n",
    "for metric in metrics:\n",
    "    blend.fit(X_train_std, y_train_log)\n",
    "    pred = blend.predict(X_test_std, metric=metric)\n",
    "    print(\"Blended {} model MSE: {:.4f}\".format(metric, mean_squared_error(y_test_log, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">標準化・対数変換後はSVR単独の方がブレンドモデルよりスコアが良い。ブレンディング法は例１同様中央値が最も良い結果となった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">《例３》重みを加えたブレンド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.0496\n",
      "SVR MSE: 0.0470\n",
      "Decision Tree MSE: 0.0527\n",
      "\n",
      "\n",
      "Blended mean model MSE: 0.0472\n",
      "Blended median model MSE: 0.0468\n",
      "Blended max model MSE: 0.0510\n",
      "Blended min model MSE: 0.0515\n",
      "Blended weighted model MSE: 0.0470\n"
     ]
    }
   ],
   "source": [
    "# 各モデルをインスタンス化\n",
    "linreg = LinearRegression()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "models = [linreg, svr, tree]\n",
    "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
    "weights = [0.4, 0.4, 0.2]\n",
    "\n",
    "# 各モデルのブレンドモデルをインスタンス化\n",
    "blend = Blending(models)\n",
    "\n",
    "# 各単一モデルの学習・推定\n",
    "for model, label in zip(models, labels):\n",
    "    model.fit(X_train_std, y_train_log)\n",
    "    pred = model.predict(X_test_std)\n",
    "    print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# ブレンドモデルの学習・推定\n",
    "blend.fit(X_train_std, y_train_log)\n",
    "\n",
    "metrics = ['mean', 'median', 'max', 'min', 'weighted']\n",
    "\n",
    "for metric in metrics:\n",
    "    blend.fit(X_train_std, y_train_log)\n",
    "    pred = blend.predict(X_test_std, metric=metric, weight=weights)\n",
    "    print(\"Blended {} model MSE: {:.4f}\".format(metric, mean_squared_error(y_test_log, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">《例４》SVMのカーネルをブレンド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf MSE: 0.0470\n",
      "linear MSE: 0.0496\n",
      "polynomial MSE: 0.0819\n",
      "sigmoid MSE: 895.9715\n",
      "\n",
      "\n",
      "Blended mean model MSE: 56.5664\n",
      "Blended median model MSE: 0.0577\n"
     ]
    }
   ],
   "source": [
    "# 各モデルをインスタンス化\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_poly = SVR(kernel='poly')\n",
    "svr_sig = SVR(kernel='sigmoid')\n",
    "\n",
    "\n",
    "models = [svr_rbf, svr_lin, svr_poly, svr_sig]\n",
    "labels = ['rbf', 'linear', 'polynomial', 'sigmoid']\n",
    "# weights = [0.3, 0.1, 0.2, 0.3, 0.1]\n",
    "\n",
    "# 各モデルのブレンドモデルをインスタンス化\n",
    "blend = Blending(models)\n",
    "\n",
    "# 各単一モデルの学習・推定\n",
    "for model, label in zip(models, labels):\n",
    "    model.fit(X_train_std, y_train_log)\n",
    "    pred = model.predict(X_test_std)\n",
    "    print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# ブレンドモデルの学習・推定\n",
    "blend.fit(X_train_std, y_train_log)\n",
    "\n",
    "metrics = ['mean', 'median']\n",
    "\n",
    "for metric in metrics:\n",
    "    blend.fit(X_train_std, y_train_log)\n",
    "    pred = blend.predict(X_test_std, metric=metric, weight=weights)\n",
    "    print(\"Blended {} model MSE: {:.4f}\".format(metric, mean_squared_error(y_test_log, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装\n",
    "**バギング**をスクラッチ実装し、単一モデルより精度があがる例を**最低1つ**示してください。\n",
    "\n",
    "### バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "推定結果の平均をとる部分はブレンディングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baggingクラスの実装\n",
    "\n",
    "import copy\n",
    "\n",
    "class Bagger():\n",
    "    def __init__(self, model, n_samples, n_bootstraps=10):\n",
    "        self.model = model\n",
    "        self.n_bootstraps = n_bootstraps\n",
    "        self.n_samples = n_samples\n",
    "        self.model_list = [copy.deepcopy(model) for _ in range(n_bootstraps)]  # Shallow Copyだと変数のみCopyされるため、Deepcopyでデータ毎複製\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        for i in range(self.n_bootstraps):\n",
    "            \n",
    "            bag_id = random.randint(len(X), size=self.n_samples)\n",
    "            \n",
    "            self.model_list[i].fit(X[bag_id], y[bag_id])\n",
    "\n",
    "\n",
    "    def predict(self, X, metric='mean'):\n",
    "        \n",
    "        preds = np.empty((len(X), len(self.model_list)))\n",
    "        \n",
    "        for i, model in enumerate(self.model_list):\n",
    "            preds[:, i] = model.predict(X)\n",
    "        \n",
    "        if metric == 'mean':\n",
    "            return preds.mean(axis=1)\n",
    "        elif metric == 'median':\n",
    "            return np.median(preds, axis=1)\n",
    "        elif metric == 'max':\n",
    "            return preds.max(axis=1)\n",
    "        elif metric == 'min':\n",
    "            return preds.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "単一モデルの交差検証＆推定結果\n",
      "                  train score test score\n",
      "Linear Regression   0.0485171  0.0495937\n",
      "SVR                 0.0416455  0.0470362\n",
      "Decision Tree       0.0685942  0.0770671\n",
      "\n",
      "\n",
      "バギングモデルの交差検証＆推定結果\n",
      "                  train score test score\n",
      "Linear Regression   0.0482951  0.0498268\n",
      "SVR                 0.0423308  0.0477689\n",
      "Decision Tree       0.0434625  0.0521715\n"
     ]
    }
   ],
   "source": [
    "# 各モデルをインスタンス化\n",
    "linreg = LinearRegression()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "models = [linreg, svr, tree]\n",
    "labels = ['Linear Regression', 'SVR', 'Decision Tree']\n",
    "\n",
    "results_standalone = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
    "results_bagging = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
    "\n",
    "\n",
    "# 各単一モデルの学習・推定\n",
    "for model, label in zip(models, labels):\n",
    "    \n",
    "    # 5分割交差検証\n",
    "    results_standalone['train score'][label] = cross_validate(model, X_train_std, y_train_log).mean()\n",
    "\n",
    "    # テストデータ検証\n",
    "    model.fit(X_train_std, y_train_log)\n",
    "    pred = model.predict(X_test_std)\n",
    "    results_standalone['test score'][label] = mean_squared_error(y_test_log, pred)\n",
    "    \n",
    "#     print(\"{} MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Baggingモデルの学習・推定\n",
    "\n",
    "for model, label in zip(models, labels):\n",
    "        \n",
    "    bagging = Bagger(model, n_samples=500, n_bootstraps=10)\n",
    "    \n",
    "    # 5分割交差検証\n",
    "    results_bagging['train score'][label] = cross_validate(bagging, X_train_std, y_train_log).mean()\n",
    "\n",
    "    bagging.fit(X_train_std, y_train_log)\n",
    "    pred = bagging.predict(X_test_std)\n",
    "    results_bagging['test score'][label] = mean_squared_error(y_test_log, pred)\n",
    "\n",
    "\n",
    "#     print(\"Bagged {} Train MSE: {:.4f}\".format(label, cross_validate(bagging, X_train_std, y_train_log).mean()))\n",
    "#     print(\"Bagged {} Test MSE: {:.4f}\".format(label, mean_squared_error(y_test_log, pred)))\n",
    "\n",
    "print(\"単一モデルの交差検証＆推定結果\")\n",
    "print(results_standalone)\n",
    "print('\\n')\n",
    "print(\"バギングモデルの交差検証＆推定結果\")\n",
    "print(results_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Baggingは決定木に最も影響を与えた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装\n",
    "**スタッキング**をスクラッチ実装し、単一モデルより精度があがる例を**最低1つ**示してください。<br>\n",
    "<br>\n",
    "### スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは$K_0=3, M_0=2$程度にします。<br>\n",
    "<br>\n",
    "**《学習時》**<br>\n",
    "<br>\n",
    "（ステージ 0）\n",
    "- 学習データを$K_0$個に分割する。\n",
    "- 分割した内の$(K_0-1)$個をまとめて学習用データ、残り1個を推定用データとする組み合わせが$K_0$個作れる。\n",
    "- あるモデルのインスタンスを$K_0$個用意し、異なる学習用データを使い学習する。\n",
    "- それぞれの学習済みモデルに対して、使っていない残り1個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "- さらに、異なるモデルのインスタンスも$K_0$個用意し、同様のことを行う。モデルが$M_0$個あれば、$M_0$個のブレンドデータが得られる。\n",
    "\n",
    "（ステージ $n$）\n",
    "- ステージ$n-1$のブレンドデータを$M_{n-1}$次元の特徴量を持つ学習用データと考え、$K_n$個に分割する。以下同様である。\n",
    "\n",
    "（ステージ $N$）＊最後のステージ\n",
    "- ステージ$N-1$の$M_{N-1}$個のブレンドデータを$M_{N-1}$次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "<br>\n",
    "\n",
    "**《推定時》**\n",
    "\n",
    "（ステージ 0）\n",
    "- テストデータを$K_0\\times M_0$個の学習済みモデルに入力し、$K_0\\times M_0$個の推定値を得る。これを$K_0$の軸で平均値を求め$M_0$次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $n$）\n",
    "- ステージ$n-1$で得たブレンドテストを$K_n\\times M_n$個の学習済みモデルに入力し、$K_n\\times M_n$個の推定値を得る。これを$K_n$の軸で平均値を求め$M_0$次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $N$）＊最後のステージ\n",
    "- ステージ$N-1$で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Stacked():\n",
    "    def __init__(self, base_models, final_model, k=3):\n",
    "        self.base_models = base_models\n",
    "        self.final_model = final_model\n",
    "        self.k = k\n",
    "        self.model_inst = [[copy.deepcopy(self.base_models[i]) for _ in range(k)] for i in range(len(self.base_models))]\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        kfold = KFold(n_splits=self.k, shuffle=True)\n",
    "        \n",
    "        X_train_f = np.empty((len(X), len(self.base_models)))\n",
    "        \n",
    "        for i in range(len(self.model_inst)):\n",
    "            for model, (train_id, test_id) in zip(self.model_inst[i], kfold.split(X)):\n",
    "            \n",
    "                X_train, y_train = X[train_id], y[train_id]\n",
    "                X_test, y_test = X[test_id], y[test_id]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                X_train_f[test_id, i] = model.predict(X_test)\n",
    "        \n",
    "        self.final_model.fit(X_train_f, y)\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_test_f = np.empty((len(X), len(self.base_models)))\n",
    "        \n",
    "        for i in range(len(self.model_inst)):\n",
    "            \n",
    "            pred = np.empty((len(X), self.k))\n",
    "            \n",
    "            for j, model in enumerate(self.model_inst[i]):\n",
    "                pred[:, j] = model.predict(X)\n",
    "                \n",
    "            X_test_f[:, i] = pred.mean(axis=1)\n",
    "            \n",
    "        return self.final_model.predict(X_test_f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スタッキングモデルの交差検証＆推定結果\n",
      "                  train score test score\n",
      "Linear Regression   0.0493836  0.0455039\n",
      "SVR                 0.0415591  0.0465108\n",
      "Decision Tree       0.0609494  0.0664328\n",
      "Stacked             0.0403909  0.0462007\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "stacked = Stacked([tree, svr], linreg, k=10)\n",
    "\n",
    "models = [linreg, svr, tree, stacked]\n",
    "labels = ['Linear Regression', 'SVR', 'Decision Tree', 'Stacked']\n",
    "\n",
    "results_stacked = pd.DataFrame(index=[labels], columns=['train score', 'test score'])\n",
    "\n",
    "for model, label in zip(models, labels):\n",
    "   # 5分割交差検証\n",
    "    results_stacked['train score'][label] = cross_validate(model, X_train_std, y_train_log).mean()\n",
    "\n",
    "    # テストデータ検証\n",
    "    model.fit(X_train_std, y_train_log)\n",
    "    pred = model.predict(X_test_std)\n",
    "    results_stacked['test score'][label] = mean_squared_error(y_test_log, pred)\n",
    "    \n",
    "print(\"スタッキングモデルの交差検証＆推定結果\")\n",
    "print(results_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">スタッキングモデルが単一モデルと比べ、訓練データのクロスバリデーションと検証データに対する推定共に良い結果となった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
